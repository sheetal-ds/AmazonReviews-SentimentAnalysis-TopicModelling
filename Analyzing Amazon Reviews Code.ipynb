{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcd7ce96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# imports needed and logging\n",
    "import gzip\n",
    "import gensim \n",
    "import logging\n",
    "logging.basicConfig(format=\"%(asctime)s : %(levelname)s : %(message)s\", level=logging.INFO)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3632fd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords  #stopwords\n",
    "from nltk.stem import WordNetLemmatizer  \n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "#nltk.download()\n",
    "stop_words=set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ab6eb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aeef6a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 12:34:10,314 : INFO : NumExpr defaulting to 4 threads.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cd3642",
   "metadata": {},
   "source": [
    "# Read the file\n",
    "data has ~6000 reviews of laptops on Amazon <br> basic EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dc0e28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "laptop = pd.read_excel(\"ML_project_dataset_final.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c32a189a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ProductName', 'ProductPrice', 'Rate', 'Review', 'Summary',\n",
       "       'Sentiment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptop.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "591d94a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the product price column as it is not required and contains some garbage values\n",
    "laptop = laptop.drop([\"ProductPrice\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ab57c83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductName</th>\n",
       "      <th>Rate</th>\n",
       "      <th>Review</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6864</th>\n",
       "      <td>ASUS TUF Gaming A17 with 90Whr Battery Ryzen 5...</td>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>go for it no doubt</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6865</th>\n",
       "      <td>MSI GF63 Thin Core i5 11th Gen - (8 GB/512 GB ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Absolute rubbish!</td>\n",
       "      <td>battery problem</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6866</th>\n",
       "      <td>Lenovo IdeaPad Gaming Core i5 11th Gen - (8 GB...</td>\n",
       "      <td>4</td>\n",
       "      <td>Pretty good</td>\n",
       "      <td>everything was good but the sound bit lower</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6867</th>\n",
       "      <td>Lenovo IdeaPad Gaming Core i5 11th Gen - (8 GB...</td>\n",
       "      <td>2</td>\n",
       "      <td>Bad quality</td>\n",
       "      <td>value for money 44k battery backup very poor p...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6868</th>\n",
       "      <td>Lenovo IdeaPad Gaming Core i5 11th Gen - (8 GB...</td>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>everyone saying that its worth of money but ba...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            ProductName  Rate  \\\n",
       "6864  ASUS TUF Gaming A17 with 90Whr Battery Ryzen 5...     5   \n",
       "6865  MSI GF63 Thin Core i5 11th Gen - (8 GB/512 GB ...     1   \n",
       "6866  Lenovo IdeaPad Gaming Core i5 11th Gen - (8 GB...     4   \n",
       "6867  Lenovo IdeaPad Gaming Core i5 11th Gen - (8 GB...     2   \n",
       "6868  Lenovo IdeaPad Gaming Core i5 11th Gen - (8 GB...     5   \n",
       "\n",
       "                   Review                                            Summary  \\\n",
       "6864  Best in the market!                                 go for it no doubt   \n",
       "6865    Absolute rubbish!                                    battery problem   \n",
       "6866          Pretty good        everything was good but the sound bit lower   \n",
       "6867          Bad quality  value for money 44k battery backup very poor p...   \n",
       "6868             Terrific  everyone saying that its worth of money but ba...   \n",
       "\n",
       "     Sentiment  \n",
       "6864  negative  \n",
       "6865  negative  \n",
       "6866  negative  \n",
       "6867  negative  \n",
       "6868  negative  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptop.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0e62cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4346"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(laptop[laptop.Sentiment == \"positive\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92e36a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1934"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(laptop[laptop.Sentiment == \"negative\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5811abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "588"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(laptop[laptop.Sentiment == \"neutral\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a60a83",
   "metadata": {},
   "source": [
    "# PART 1: SENTIMENT ANALYSIS\n",
    "Step 1: Data pre-processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bd80437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input_csv(input_file):\n",
    "        \"\"\"This method reads the input .txt file\"\"\"\n",
    "        logging.info(\"reading file {0}...this may take a while\".format(input_file))\n",
    "        with open(input_file, 'r') as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if (i % 10000 == 0):\n",
    "                    logging.info(\"read {0} reviews\".format(i))\n",
    "                yield gensim.utils.simple_preprocess(line, min_len=0, max_len=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfdf51b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For word2vec I would like to change everything to lower case - will use \n",
    "class DocReader_csv:\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for line in read_input_csv(self.filename):\n",
    "            yield line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea165a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>poor delivery service denied to follow open bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>worst product ever seen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>display not working yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>got it for just 41500 but all excitment went i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i brought this laptop for 51490 offer price wa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  poor delivery service denied to follow open bo...\n",
       "1                            worst product ever seen\n",
       "2                            display not working yet\n",
       "3  got it for just 41500 but all excitment went i...\n",
       "4  i brought this laptop for 51490 offer price wa..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reviews.csv is a subset of original file, it contains only the reviews column \n",
    "#(since we have to send only the reviews to train word2vec)\n",
    "test_df = pd.read_csv(\"Reviews.csv\", header = None)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "282e34b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "laptop_reader = DocReader_csv(\"Reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2703e19",
   "metadata": {},
   "source": [
    "# Step 2: Training Word2Vec model <br> \n",
    "Training the Word2Vec model to create word embeddings of vector with 100 neurons <br>\n",
    "We are using 5 epochs, window size 10 and vector size 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17d163f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 12:37:24,486 : INFO : collecting all words and their counts\n",
      "2023-03-23 12:37:24,497 : INFO : reading file Reviews.csv...this may take a while\n",
      "2023-03-23 12:37:24,499 : INFO : read 0 reviews\n",
      "2023-03-23 12:37:24,501 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-03-23 12:37:24,792 : INFO : collected 4368 word types from a corpus of 130857 raw words and 6869 sentences\n",
      "2023-03-23 12:37:24,792 : INFO : Creating a fresh vocabulary\n",
      "2023-03-23 12:37:24,812 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 4134 unique words (94.64% of original 4368, drops 234)', 'datetime': '2023-03-23T12:37:24.812147', 'gensim': '4.3.1', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2023-03-23 12:37:24,813 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 130623 word corpus (99.82% of original 130857, drops 234)', 'datetime': '2023-03-23T12:37:24.813277', 'gensim': '4.3.1', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2023-03-23 12:37:24,879 : INFO : deleting the raw counts dictionary of 4368 items\n",
      "2023-03-23 12:37:24,880 : INFO : sample=0.001 downsamples 62 most-common words\n",
      "2023-03-23 12:37:24,881 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 92692.21237574205 word corpus (71.0%% of prior 130623)', 'datetime': '2023-03-23T12:37:24.881759', 'gensim': '4.3.1', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2023-03-23 12:37:24,993 : INFO : estimated required memory for 4134 words and 100 dimensions: 5374200 bytes\n",
      "2023-03-23 12:37:24,995 : INFO : resetting layer weights\n",
      "2023-03-23 12:37:25,013 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-03-23T12:37:25.013702', 'gensim': '4.3.1', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2023-03-23 12:37:25,014 : INFO : Word2Vec lifecycle event {'msg': 'training model with 10 workers on 4134 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=5 window=10 shrink_windows=True', 'datetime': '2023-03-23T12:37:25.014818', 'gensim': '4.3.1', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2023-03-23 12:37:25,027 : INFO : reading file Reviews.csv...this may take a while\n",
      "2023-03-23 12:37:25,029 : INFO : read 0 reviews\n",
      "2023-03-23 12:37:25,515 : INFO : EPOCH 0: training on 130857 raw words (92805 effective words) took 0.5s, 190600 effective words/s\n",
      "2023-03-23 12:37:25,519 : INFO : reading file Reviews.csv...this may take a while\n",
      "2023-03-23 12:37:25,520 : INFO : read 0 reviews\n",
      "2023-03-23 12:37:26,100 : INFO : EPOCH 1: training on 130857 raw words (92673 effective words) took 0.6s, 159424 effective words/s\n",
      "2023-03-23 12:37:26,107 : INFO : reading file Reviews.csv...this may take a while\n",
      "2023-03-23 12:37:26,108 : INFO : read 0 reviews\n",
      "2023-03-23 12:37:26,757 : INFO : EPOCH 2: training on 130857 raw words (92600 effective words) took 0.6s, 142512 effective words/s\n",
      "2023-03-23 12:37:26,762 : INFO : reading file Reviews.csv...this may take a while\n",
      "2023-03-23 12:37:26,764 : INFO : read 0 reviews\n",
      "2023-03-23 12:37:27,298 : INFO : EPOCH 3: training on 130857 raw words (92706 effective words) took 0.5s, 173052 effective words/s\n",
      "2023-03-23 12:37:27,303 : INFO : reading file Reviews.csv...this may take a while\n",
      "2023-03-23 12:37:27,304 : INFO : read 0 reviews\n",
      "2023-03-23 12:37:27,847 : INFO : EPOCH 4: training on 130857 raw words (92698 effective words) took 0.5s, 170557 effective words/s\n",
      "2023-03-23 12:37:27,848 : INFO : Word2Vec lifecycle event {'msg': 'training on 654285 raw words (463482 effective words) took 2.8s, 163663 effective words/s', 'datetime': '2023-03-23T12:37:27.848220', 'gensim': '4.3.1', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'train'}\n",
      "2023-03-23 12:37:27,849 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=4134, vector_size=100, alpha=0.025>', 'datetime': '2023-03-23T12:37:27.849958', 'gensim': '4.3.1', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(1)\n",
    "model = gensim.models.Word2Vec(laptop_reader,vector_size=100,window=10,min_count=2,workers=10,sg =1, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03737777",
   "metadata": {},
   "source": [
    "Exploring how the model has trained by finding similar words, similarities and word vectors. We can also get mean vector of a review by using .getmeanvector() method of gensim word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f08c281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hour', 0.7639968991279602),\n",
       " ('hardly', 0.7629243731498718),\n",
       " ('batterys', 0.75520920753479),\n",
       " ('five', 0.753623366355896),\n",
       " ('approx', 0.7521011233329773),\n",
       " ('charged', 0.7514491081237793),\n",
       " ('continue', 0.747665286064148),\n",
       " ('performancelook', 0.743069052696228),\n",
       " ('disappointing', 0.7402222156524658),\n",
       " ('half', 0.7396056652069092)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word('battery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdb05792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('passwords', 0.6932527422904968),\n",
       " ('productdont', 0.691546618938446),\n",
       " ('hate', 0.680219292640686),\n",
       " ('productsnot', 0.6730890274047852),\n",
       " ('soundcamera', 0.6725764870643616),\n",
       " ('productbut', 0.6589723825454712),\n",
       " ('verry', 0.6574622988700867),\n",
       " ('hes', 0.6543365716934204),\n",
       " ('durability', 0.6525306105613708),\n",
       " ('stucks', 0.6489543914794922)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word('bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "828224fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tuf', 0.8203996419906616),\n",
       " ('laptopi', 0.7912247776985168),\n",
       " ('rog', 0.7774960994720459),\n",
       " ('performancedefinately', 0.7505925893783569),\n",
       " ('alsolike', 0.7430764436721802),\n",
       " ('compared', 0.7390070557594299),\n",
       " ('buybut', 0.7389929294586182),\n",
       " ('thisfor', 0.7375590801239014),\n",
       " ('brand', 0.7354016900062561),\n",
       " ('save', 0.730320930480957)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word('asus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1edcde7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lap', 0.8038808107376099),\n",
       " ('marvelous', 0.7990869879722595),\n",
       " ('flipkartfor', 0.7963902354240417),\n",
       " ('prize', 0.7884438037872314),\n",
       " ('opinion', 0.7876623868942261),\n",
       " ('professional', 0.784482479095459),\n",
       " ('goodotherwise', 0.7821691632270813),\n",
       " ('performan', 0.7817632555961609),\n",
       " ('category', 0.7807818651199341),\n",
       " ('itin', 0.7802942395210266)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word('laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5bea22f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.2125267 , -0.05820439,  0.07371209,  0.27839366,  0.14030728,\n",
       "       -0.17760277,  0.36471093,  0.4940261 , -0.62416875, -0.18948382,\n",
       "        0.00794867, -0.24955384,  0.02434595,  0.04067629, -0.0570067 ,\n",
       "       -0.07151498,  0.05093838, -0.03627001,  0.13717198, -0.7875858 ,\n",
       "        0.33736297,  0.09448305,  0.1782909 ,  0.01284182, -0.29513294,\n",
       "       -0.50803906, -0.30869094,  0.36041927, -0.05698458,  0.10190786,\n",
       "       -0.10267562, -0.06550863,  0.47044995,  0.07716373, -0.2565548 ,\n",
       "        0.19869976,  0.19983014, -0.23264438, -0.20578265, -0.44895393,\n",
       "       -0.16036768, -0.13021971, -0.11155153,  0.23314124,  0.07599704,\n",
       "       -0.33071506,  0.27342582, -0.03238205,  0.35274437, -0.03329845,\n",
       "       -0.10408803, -0.04607852,  0.07802533,  0.17774816, -0.08299491,\n",
       "        0.06688396,  0.21433742, -0.28505772,  0.04111367,  0.18173581,\n",
       "        0.02245242, -0.06139115,  0.08661313,  0.18410699, -0.48372492,\n",
       "        0.2909853 ,  0.10571846,  0.35606828, -0.5062379 ,  0.1998058 ,\n",
       "       -0.16355458,  0.02866764, -0.20821112,  0.19169214,  0.01569088,\n",
       "        0.03121443, -0.05324258,  0.19343399, -0.33407295,  0.06857178,\n",
       "        0.01802356,  0.35737562, -0.10482359,  0.5292971 , -0.25526297,\n",
       "       -0.0684476 ,  0.26947117,  0.22609442,  0.15917955,  0.10167849,\n",
       "        0.35251635, -0.28593954, -0.27280316,  0.1065686 , -0.0670064 ,\n",
       "        0.04459484,  0.10822919, -0.12754098, -0.07105471, -0.02227221],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.get_vector('display')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "724b72b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.15634052,  0.01959629,  0.08202243, ..., -0.28022295,\n",
       "        -0.1994208 , -0.10857232],\n",
       "       [-0.1927779 ,  0.17532629, -0.06230302, ..., -0.27812177,\n",
       "         0.11040565, -0.08919425],\n",
       "       [ 0.21301048,  0.21140471, -0.08945211, ..., -0.07272013,\n",
       "         0.09439408, -0.29617742],\n",
       "       ...,\n",
       "       [-0.05405443,  0.10502027, -0.01348446, ..., -0.16980067,\n",
       "         0.05838868, -0.10922109],\n",
       "       [-0.01530092,  0.12786217,  0.0459125 , ..., -0.17471702,\n",
       "         0.01233461, -0.08453312],\n",
       "       [-0.03282405,  0.13089956,  0.01083328, ..., -0.1635755 ,\n",
       "         0.00460657, -0.07758429]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vectors #This is full array of vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d9e55a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is': 0,\n",
       " 'and': 1,\n",
       " 'the': 2,\n",
       " 'laptop': 3,\n",
       " 'good': 4,\n",
       " 'for': 5,\n",
       " 'this': 6,\n",
       " 'it': 7,\n",
       " 'i': 8,\n",
       " 'to': 9,\n",
       " 'very': 10,\n",
       " 'battery': 11,\n",
       " 'not': 12,\n",
       " 'in': 13,\n",
       " 'a': 14,\n",
       " 'but': 15,\n",
       " 'product': 16,\n",
       " 'of': 17,\n",
       " 'performance': 18,\n",
       " 'with': 19,\n",
       " 'its': 20,\n",
       " 'best': 21,\n",
       " 'you': 22,\n",
       " 'gaming': 23,\n",
       " 'quality': 24,\n",
       " 'price': 25,\n",
       " 'display': 26,\n",
       " 'on': 27,\n",
       " 'at': 28,\n",
       " 'money': 29,\n",
       " 'backup': 30,\n",
       " 'can': 31,\n",
       " 'only': 32,\n",
       " 'nice': 33,\n",
       " 'are': 34,\n",
       " 'so': 35,\n",
       " 'have': 36,\n",
       " 'buy': 37,\n",
       " 'was': 38,\n",
       " 'all': 39,\n",
       " 'as': 40,\n",
       " 'just': 41,\n",
       " 'after': 42,\n",
       " 'also': 43,\n",
       " 'value': 44,\n",
       " 'that': 45,\n",
       " 'no': 46,\n",
       " 'if': 47,\n",
       " 'one': 48,\n",
       " 'my': 49,\n",
       " 'go': 50,\n",
       " 'awesome': 51,\n",
       " 'dont': 52,\n",
       " 'great': 53,\n",
       " 'range': 54,\n",
       " 'bad': 55,\n",
       " 'issue': 56,\n",
       " 'like': 57,\n",
       " 'k': 58,\n",
       " 'working': 59,\n",
       " 'low': 60,\n",
       " 'than': 61,\n",
       " 'hours': 62,\n",
       " 'screen': 63,\n",
       " 'overall': 64,\n",
       " 'using': 65,\n",
       " 'will': 66,\n",
       " 'from': 67,\n",
       " 'use': 68,\n",
       " 'more': 69,\n",
       " 'fast': 70,\n",
       " 'problem': 71,\n",
       " 'got': 72,\n",
       " 'really': 73,\n",
       " 'better': 74,\n",
       " 'be': 75,\n",
       " 'other': 76,\n",
       " 'sound': 77,\n",
       " 'keyboard': 78,\n",
       " 'ram': 79,\n",
       " 'worst': 80,\n",
       " 'or': 81,\n",
       " 'days': 82,\n",
       " 'flipkart': 83,\n",
       " 'am': 84,\n",
       " 'budget': 85,\n",
       " 'design': 86,\n",
       " 'even': 87,\n",
       " 'gb': 88,\n",
       " 'has': 89,\n",
       " 'some': 90,\n",
       " 'build': 91,\n",
       " 'work': 92,\n",
       " 'too': 93,\n",
       " 'poor': 94,\n",
       " 'which': 95,\n",
       " 'experience': 96,\n",
       " 'beast': 97,\n",
       " 'everything': 98,\n",
       " 'any': 99,\n",
       " 'while': 100,\n",
       " 'when': 101,\n",
       " 'games': 102,\n",
       " 'u': 103,\n",
       " 'get': 104,\n",
       " 'delivery': 105,\n",
       " 'ok': 106,\n",
       " 'under': 107,\n",
       " 'usage': 108,\n",
       " 'up': 109,\n",
       " 'much': 110,\n",
       " 'normal': 111,\n",
       " 'there': 112,\n",
       " 'heating': 113,\n",
       " 'review': 114,\n",
       " 'smooth': 115,\n",
       " 'life': 116,\n",
       " 'average': 117,\n",
       " 'about': 118,\n",
       " 'hz': 119,\n",
       " 'hrs': 120,\n",
       " 'time': 121,\n",
       " 'excellent': 122,\n",
       " 'amazing': 123,\n",
       " 'issues': 124,\n",
       " 'hp': 125,\n",
       " 'because': 126,\n",
       " 'high': 127,\n",
       " 'your': 128,\n",
       " 'day': 129,\n",
       " 'worth': 130,\n",
       " 'then': 131,\n",
       " 'asus': 132,\n",
       " 'office': 133,\n",
       " 'ssd': 134,\n",
       " 'months': 135,\n",
       " 'thing': 136,\n",
       " 'processor': 137,\n",
       " 'ryzen': 138,\n",
       " 'by': 139,\n",
       " 'used': 140,\n",
       " 'me': 141,\n",
       " 'been': 142,\n",
       " 'windows': 143,\n",
       " 'service': 144,\n",
       " 'now': 145,\n",
       " 'h': 146,\n",
       " 'graphics': 147,\n",
       " 'purchase': 148,\n",
       " 'fps': 149,\n",
       " 'wifi': 150,\n",
       " 'around': 151,\n",
       " 'look': 152,\n",
       " 'less': 153,\n",
       " 'power': 154,\n",
       " 'heavy': 155,\n",
       " 'well': 156,\n",
       " 'msi': 157,\n",
       " 'love': 158,\n",
       " 'without': 159,\n",
       " 'super': 160,\n",
       " 'little': 161,\n",
       " 'need': 162,\n",
       " 'speaker': 163,\n",
       " 'laptops': 164,\n",
       " 'month': 165,\n",
       " 'bit': 166,\n",
       " 'play': 167,\n",
       " 'speed': 168,\n",
       " 'game': 169,\n",
       " 'first': 170,\n",
       " 'looks': 171,\n",
       " 'give': 172,\n",
       " 'loved': 173,\n",
       " 'playing': 174,\n",
       " 'happy': 175,\n",
       " 'gives': 176,\n",
       " 'every': 177,\n",
       " 'fine': 178,\n",
       " 'light': 179,\n",
       " 'comes': 180,\n",
       " 'waste': 181,\n",
       " 'big': 182,\n",
       " 'looking': 183,\n",
       " 'cant': 184,\n",
       " 'works': 185,\n",
       " 'could': 186,\n",
       " 'doesnt': 187,\n",
       " 'heat': 188,\n",
       " 'they': 189,\n",
       " 'want': 190,\n",
       " 'charging': 191,\n",
       " 'gta': 192,\n",
       " 'hour': 193,\n",
       " 'an': 194,\n",
       " 'cons': 195,\n",
       " 'lag': 196,\n",
       " 'update': 197,\n",
       " 'do': 198,\n",
       " 'fan': 199,\n",
       " 'run': 200,\n",
       " 'settings': 201,\n",
       " 'out': 202,\n",
       " 'back': 203,\n",
       " 'satisfied': 204,\n",
       " 'full': 205,\n",
       " 'we': 206,\n",
       " 'expected': 207,\n",
       " 'ms': 208,\n",
       " 'would': 209,\n",
       " 'same': 210,\n",
       " 'perfect': 211,\n",
       " 'week': 212,\n",
       " 'bought': 213,\n",
       " 'most': 214,\n",
       " 'rtx': 215,\n",
       " 'system': 216,\n",
       " 'card': 217,\n",
       " 'upto': 218,\n",
       " 'segment': 219,\n",
       " 'ever': 220,\n",
       " 'camera': 221,\n",
       " 'things': 222,\n",
       " 'superb': 223,\n",
       " 'should': 224,\n",
       " 'backlit': 225,\n",
       " 'speakers': 226,\n",
       " 'had': 227,\n",
       " 'over': 228,\n",
       " 'think': 229,\n",
       " 'getting': 230,\n",
       " 'say': 231,\n",
       " 'quite': 232,\n",
       " 'weight': 233,\n",
       " 'charge': 234,\n",
       " 'enough': 235,\n",
       " 'coding': 236,\n",
       " 'plastic': 237,\n",
       " 'rate': 238,\n",
       " 'device': 239,\n",
       " 'brightness': 240,\n",
       " 'both': 241,\n",
       " 'smoothly': 242,\n",
       " 'slot': 243,\n",
       " 'writing': 244,\n",
       " 'refresh': 245,\n",
       " 'mark': 246,\n",
       " 'gen': 247,\n",
       " 'th': 248,\n",
       " 'slow': 249,\n",
       " 'programming': 250,\n",
       " 'editing': 251,\n",
       " 'see': 252,\n",
       " 'last': 253,\n",
       " 'off': 254,\n",
       " 'deal': 255,\n",
       " 'decent': 256,\n",
       " 'machine': 257,\n",
       " 'im': 258,\n",
       " 'buying': 259,\n",
       " 'though': 260,\n",
       " 'totally': 261,\n",
       " 'please': 262,\n",
       " 'hr': 263,\n",
       " 'pros': 264,\n",
       " 'till': 265,\n",
       " 'built': 266,\n",
       " 'cpu': 267,\n",
       " 'disappointed': 268,\n",
       " 'still': 269,\n",
       " 'properly': 270,\n",
       " 'point': 271,\n",
       " 'expect': 272,\n",
       " 'gpu': 273,\n",
       " 'feel': 274,\n",
       " 'body': 275,\n",
       " 'who': 276,\n",
       " 'always': 277,\n",
       " 'pretty': 278,\n",
       " 'valorant': 279,\n",
       " 'found': 280,\n",
       " 'does': 281,\n",
       " 'easily': 282,\n",
       " 'except': 283,\n",
       " 'almost': 284,\n",
       " 'during': 285,\n",
       " 'hdd': 286,\n",
       " 'thats': 287,\n",
       " 'installed': 288,\n",
       " 'many': 289,\n",
       " 'top': 290,\n",
       " 'level': 291,\n",
       " 'what': 292,\n",
       " 'such': 293,\n",
       " 'max': 294,\n",
       " 'video': 295,\n",
       " 'few': 296,\n",
       " 'okay': 297,\n",
       " 'sometimes': 298,\n",
       " 'recommend': 299,\n",
       " 'software': 300,\n",
       " 'compared': 301,\n",
       " 'thanks': 302,\n",
       " 'giving': 303,\n",
       " 'intel': 304,\n",
       " 'open': 305,\n",
       " 'wise': 306,\n",
       " 'support': 307,\n",
       " 'keys': 308,\n",
       " 'times': 309,\n",
       " 'audio': 310,\n",
       " 'new': 311,\n",
       " 'since': 312,\n",
       " 'must': 313,\n",
       " 'know': 314,\n",
       " 'browsing': 315,\n",
       " 'runs': 316,\n",
       " 'students': 317,\n",
       " 'recommended': 318,\n",
       " 'started': 319,\n",
       " 'purchased': 320,\n",
       " 'amd': 321,\n",
       " 'return': 322,\n",
       " 'warranty': 323,\n",
       " 'gtx': 324,\n",
       " 'nvidia': 325,\n",
       " 'available': 326,\n",
       " 'mouse': 327,\n",
       " 'lasts': 328,\n",
       " 'given': 329,\n",
       " 'charger': 330,\n",
       " 'faced': 331,\n",
       " 'sale': 332,\n",
       " 'acer': 333,\n",
       " 'played': 334,\n",
       " 'needs': 335,\n",
       " 'facing': 336,\n",
       " 'rest': 337,\n",
       " 'below': 338,\n",
       " 'online': 339,\n",
       " 'products': 340,\n",
       " 'customer': 341,\n",
       " 'within': 342,\n",
       " 'pad': 343,\n",
       " 'powerful': 344,\n",
       " 'another': 345,\n",
       " 'seems': 346,\n",
       " 'option': 347,\n",
       " 'thermals': 348,\n",
       " 'choice': 349,\n",
       " 'these': 350,\n",
       " 'touchpad': 351,\n",
       " 'before': 352,\n",
       " 'absolutely': 353,\n",
       " 'cooling': 354,\n",
       " 'key': 355,\n",
       " 'type': 356,\n",
       " 'cool': 357,\n",
       " 'start': 358,\n",
       " 'far': 359,\n",
       " 'doubt': 360,\n",
       " 'replacement': 361,\n",
       " 'otherwise': 362,\n",
       " 'features': 363,\n",
       " 'con': 364,\n",
       " 'never': 365,\n",
       " 'purpose': 366,\n",
       " 'tested': 367,\n",
       " 'provide': 368,\n",
       " 'feels': 369,\n",
       " 'v': 370,\n",
       " 'running': 371,\n",
       " 'bleeding': 372,\n",
       " 'although': 373,\n",
       " 'coming': 374,\n",
       " 'find': 375,\n",
       " 'gets': 376,\n",
       " 'min': 377,\n",
       " 'basic': 378,\n",
       " 'cost': 379,\n",
       " 'may': 380,\n",
       " 'purchasing': 381,\n",
       " 'upgrade': 382,\n",
       " 'box': 383,\n",
       " 'seconds': 384,\n",
       " 'thank': 385,\n",
       " 'made': 386,\n",
       " 'make': 387,\n",
       " 'core': 388,\n",
       " 'long': 389,\n",
       " 'port': 390,\n",
       " 'draining': 391,\n",
       " 'handle': 392,\n",
       " 'going': 393,\n",
       " 'didnt': 394,\n",
       " 'p': 395,\n",
       " 'specs': 396,\n",
       " 'color': 397,\n",
       " 'brand': 398,\n",
       " 'usb': 399,\n",
       " 'hanging': 400,\n",
       " 'model': 401,\n",
       " 'lot': 402,\n",
       " 'boot': 403,\n",
       " 'multitasking': 404,\n",
       " 'lappy': 405,\n",
       " 'anything': 406,\n",
       " 'extremely': 407,\n",
       " 'free': 408,\n",
       " 'temperature': 409,\n",
       " 'considering': 410,\n",
       " 'their': 411,\n",
       " 'drains': 412,\n",
       " 'highly': 413,\n",
       " 'purple': 414,\n",
       " 'between': 415,\n",
       " 'lags': 416,\n",
       " 'dell': 417,\n",
       " 'per': 418,\n",
       " 'graphic': 419,\n",
       " 'down': 420,\n",
       " 'm': 421,\n",
       " 'already': 422,\n",
       " 'single': 423,\n",
       " 'received': 424,\n",
       " 'guys': 425,\n",
       " 'mode': 426,\n",
       " 'people': 427,\n",
       " 'havent': 428,\n",
       " 'frame': 429,\n",
       " 'due': 430,\n",
       " 'wont': 431,\n",
       " 'rgb': 432,\n",
       " 'especially': 433,\n",
       " 'lower': 434,\n",
       " 'suggest': 435,\n",
       " 'took': 436,\n",
       " 'lenovo': 437,\n",
       " 'take': 438,\n",
       " 'configuration': 439,\n",
       " 'r': 440,\n",
       " 'iam': 441,\n",
       " 'nothing': 442,\n",
       " 'hub': 443,\n",
       " 'lagging': 444,\n",
       " 'w': 445,\n",
       " 'again': 446,\n",
       " 'went': 447,\n",
       " 'daily': 448,\n",
       " 'external': 449,\n",
       " 'else': 450,\n",
       " 'finger': 451,\n",
       " 'simple': 452,\n",
       " 'tried': 453,\n",
       " 'two': 454,\n",
       " 'care': 455,\n",
       " 'heats': 456,\n",
       " 'button': 457,\n",
       " 'loud': 458,\n",
       " 'choose': 459,\n",
       " 'fingerprint': 460,\n",
       " 'old': 461,\n",
       " 'definitely': 462,\n",
       " 'soo': 463,\n",
       " 'worse': 464,\n",
       " 'c': 465,\n",
       " 'task': 466,\n",
       " 'second': 467,\n",
       " 'weeks': 468,\n",
       " 'drain': 469,\n",
       " 'black': 470,\n",
       " 'delivered': 471,\n",
       " 'install': 472,\n",
       " 'side': 473,\n",
       " 'company': 474,\n",
       " 'problems': 475,\n",
       " 'multiple': 476,\n",
       " 'size': 477,\n",
       " 'tuf': 478,\n",
       " 'medium': 479,\n",
       " 'here': 480,\n",
       " 'sure': 481,\n",
       " 'fans': 482,\n",
       " 'premium': 483,\n",
       " 'user': 484,\n",
       " 'order': 485,\n",
       " 'sec': 486,\n",
       " 'date': 487,\n",
       " 'additional': 488,\n",
       " 'billion': 489,\n",
       " 'extra': 490,\n",
       " 'major': 491,\n",
       " 'makes': 492,\n",
       " 'small': 493,\n",
       " 'thought': 494,\n",
       " 'wow': 495,\n",
       " 'market': 496,\n",
       " 'pc': 497,\n",
       " 'purposes': 498,\n",
       " 'videos': 499,\n",
       " 'defective': 500,\n",
       " 'having': 501,\n",
       " 'change': 502,\n",
       " 'done': 503,\n",
       " 'booting': 504,\n",
       " 'softwares': 505,\n",
       " 'consider': 506,\n",
       " 'fantastic': 507,\n",
       " 'felt': 508,\n",
       " 'job': 509,\n",
       " 'hang': 510,\n",
       " 'aaa': 511,\n",
       " 'gamer': 512,\n",
       " 'came': 513,\n",
       " 'year': 514,\n",
       " 'home': 515,\n",
       " 'backlight': 516,\n",
       " 'doing': 517,\n",
       " 'internet': 518,\n",
       " 'something': 519,\n",
       " 'where': 520,\n",
       " 'concern': 521,\n",
       " 's': 522,\n",
       " 'colour': 523,\n",
       " 'uses': 524,\n",
       " 'mhz': 525,\n",
       " 'tasks': 526,\n",
       " 'come': 527,\n",
       " 'inch': 528,\n",
       " 'notch': 529,\n",
       " 'however': 530,\n",
       " 'replaced': 531,\n",
       " 'provided': 532,\n",
       " 'avoid': 533,\n",
       " 'them': 534,\n",
       " 'minutes': 535,\n",
       " 'pavilion': 536,\n",
       " 'adaptor': 537,\n",
       " 'drawback': 538,\n",
       " 'ultra': 539,\n",
       " 'above': 540,\n",
       " 'plus': 541,\n",
       " 'person': 542,\n",
       " 'how': 543,\n",
       " 'thermal': 544,\n",
       " 'slim': 545,\n",
       " 'storage': 546,\n",
       " 'watching': 547,\n",
       " 'youre': 548,\n",
       " 'data': 549,\n",
       " 'hardly': 550,\n",
       " 'webcam': 551,\n",
       " 'reviews': 552,\n",
       " 'actually': 553,\n",
       " 'tb': 554,\n",
       " 'drivers': 555,\n",
       " 'student': 556,\n",
       " 'nearly': 557,\n",
       " 'version': 558,\n",
       " 'microsoft': 559,\n",
       " 't': 560,\n",
       " 'add': 561,\n",
       " 'compare': 562,\n",
       " 'nd': 563,\n",
       " 'touch': 564,\n",
       " 'finally': 565,\n",
       " 'future': 566,\n",
       " 'opening': 567,\n",
       " 'cheap': 568,\n",
       " 'seller': 569,\n",
       " 'were': 570,\n",
       " 'yes': 571,\n",
       " 'ive': 572,\n",
       " 'fabulous': 573,\n",
       " 'control': 574,\n",
       " 'bt': 575,\n",
       " 'others': 576,\n",
       " 'automatically': 577,\n",
       " 'options': 578,\n",
       " 'usually': 579,\n",
       " 'hinge': 580,\n",
       " 'simply': 581,\n",
       " 'specifications': 582,\n",
       " 'did': 583,\n",
       " 'performs': 584,\n",
       " 'mind': 585,\n",
       " 'ips': 586,\n",
       " 'multi': 587,\n",
       " 'bluetooth': 588,\n",
       " 'negative': 589,\n",
       " 'keep': 590,\n",
       " 'perform': 591,\n",
       " 'tell': 592,\n",
       " 'face': 593,\n",
       " 'users': 594,\n",
       " 'seen': 595,\n",
       " 'keypad': 596,\n",
       " 'impressed': 597,\n",
       " 'set': 598,\n",
       " 'easy': 599,\n",
       " 'right': 600,\n",
       " 'total': 601,\n",
       " 'designing': 602,\n",
       " 'check': 603,\n",
       " 'processing': 604,\n",
       " 'says': 605,\n",
       " 'might': 606,\n",
       " 'quick': 607,\n",
       " 'print': 608,\n",
       " 'approx': 609,\n",
       " 'packaging': 610,\n",
       " 'window': 611,\n",
       " 'performing': 612,\n",
       " 'according': 613,\n",
       " 'boots': 614,\n",
       " 'lap': 615,\n",
       " 'terrific': 616,\n",
       " 'goes': 617,\n",
       " 'why': 618,\n",
       " 'plugin': 619,\n",
       " 'possible': 620,\n",
       " 'perfectly': 621,\n",
       " 'suddenly': 622,\n",
       " 'etc': 623,\n",
       " 'volume': 624,\n",
       " 'chrome': 625,\n",
       " 'kg': 626,\n",
       " 'web': 627,\n",
       " 'turn': 628,\n",
       " 'base': 629,\n",
       " 'titles': 630,\n",
       " 'lit': 631,\n",
       " 'anyone': 632,\n",
       " 'proper': 633,\n",
       " 'upgraded': 634,\n",
       " 'broken': 635,\n",
       " 'updates': 636,\n",
       " 'killer': 637,\n",
       " 'improved': 638,\n",
       " 'transfer': 639,\n",
       " 'correct': 640,\n",
       " 'noise': 641,\n",
       " 'nvme': 642,\n",
       " 'condition': 643,\n",
       " 'boy': 644,\n",
       " 'part': 645,\n",
       " 'terms': 646,\n",
       " 'itself': 647,\n",
       " 'instead': 648,\n",
       " 'yet': 649,\n",
       " 'clear': 650,\n",
       " 'victus': 651,\n",
       " 'annoying': 652,\n",
       " 'try': 653,\n",
       " 'studio': 654,\n",
       " 'connect': 655,\n",
       " 'capacity': 656,\n",
       " 'shows': 657,\n",
       " 'those': 658,\n",
       " 'faster': 659,\n",
       " 'leptop': 660,\n",
       " 'through': 661,\n",
       " 'mid': 662,\n",
       " 'x': 663,\n",
       " 'being': 664,\n",
       " 'probably': 665,\n",
       " 'pay': 666,\n",
       " 'able': 667,\n",
       " 'butter': 668,\n",
       " 'continuously': 669,\n",
       " 'generation': 670,\n",
       " 'blindly': 671,\n",
       " 'phone': 672,\n",
       " 'brands': 673,\n",
       " 'watt': 674,\n",
       " 'large': 675,\n",
       " 'osm': 676,\n",
       " 'improve': 677,\n",
       " 'switch': 678,\n",
       " 'excited': 679,\n",
       " 'memory': 680,\n",
       " 'trust': 681,\n",
       " 'kinda': 682,\n",
       " 'installation': 683,\n",
       " 'worry': 684,\n",
       " 'drops': 685,\n",
       " 'regarding': 686,\n",
       " 'goodbut': 687,\n",
       " 'shutdown': 688,\n",
       " 'instant': 689,\n",
       " 'rating': 690,\n",
       " 'ports': 691,\n",
       " 'lid': 692,\n",
       " 'takes': 693,\n",
       " 'movies': 694,\n",
       " 'bbd': 695,\n",
       " 'important': 696,\n",
       " 'goodi': 697,\n",
       " 'honest': 698,\n",
       " 'awsome': 699,\n",
       " 'saving': 700,\n",
       " 'cannot': 701,\n",
       " 'plug': 702,\n",
       " 'stopped': 703,\n",
       " 'aspects': 704,\n",
       " 'series': 705,\n",
       " 'replace': 706,\n",
       " 'pathetic': 707,\n",
       " 'bcoz': 708,\n",
       " 'refund': 709,\n",
       " 'wobble': 710,\n",
       " 'louder': 711,\n",
       " 'write': 712,\n",
       " 'trackpad': 713,\n",
       " 'today': 714,\n",
       " 'nor': 715,\n",
       " 'near': 716,\n",
       " 'offer': 717,\n",
       " 'thinking': 718,\n",
       " 'put': 719,\n",
       " 'kind': 720,\n",
       " 'pro': 721,\n",
       " 'center': 722,\n",
       " 'hard': 723,\n",
       " 'help': 724,\n",
       " 'rdr': 725,\n",
       " 'friendly': 726,\n",
       " 'ac': 727,\n",
       " 'mins': 728,\n",
       " 'half': 729,\n",
       " 'wonderful': 730,\n",
       " 'apps': 731,\n",
       " 'connecting': 732,\n",
       " 'amount': 733,\n",
       " 'surfing': 734,\n",
       " 'website': 735,\n",
       " 'fo': 736,\n",
       " 'period': 737,\n",
       " 'multimedia': 738,\n",
       " 'turned': 739,\n",
       " 'hardware': 740,\n",
       " 'air': 741,\n",
       " 'he': 742,\n",
       " 'once': 743,\n",
       " 'cam': 744,\n",
       " 'liked': 745,\n",
       " 'hangs': 746,\n",
       " 'save': 747,\n",
       " 'unable': 748,\n",
       " 'carefully': 749,\n",
       " 'theres': 750,\n",
       " 'late': 751,\n",
       " 'minor': 752,\n",
       " 'decision': 753,\n",
       " 'sensor': 754,\n",
       " 'press': 755,\n",
       " 'dead': 756,\n",
       " 'absolute': 757,\n",
       " 'useful': 758,\n",
       " 'gap': 759,\n",
       " 'longer': 760,\n",
       " 'soon': 761,\n",
       " 'serious': 762,\n",
       " 'way': 763,\n",
       " 'affordable': 764,\n",
       " 'study': 765,\n",
       " 'compromise': 766,\n",
       " 'class': 767,\n",
       " 'avg': 768,\n",
       " 'hexa': 769,\n",
       " 'setting': 770,\n",
       " 'three': 771,\n",
       " 'red': 772,\n",
       " 'cheaper': 773,\n",
       " 'crisp': 774,\n",
       " 'default': 775,\n",
       " 'showing': 776,\n",
       " 'outstanding': 777,\n",
       " 'combo': 778,\n",
       " 'tasking': 779,\n",
       " 'main': 780,\n",
       " 'yesterday': 781,\n",
       " 'desktop': 782,\n",
       " 'end': 783,\n",
       " 'dedicated': 784,\n",
       " 'maximum': 785,\n",
       " 'magnet': 786,\n",
       " 'each': 787,\n",
       " 'literally': 788,\n",
       " 'wrong': 789,\n",
       " 'deliver': 790,\n",
       " 'monitor': 791,\n",
       " 'ordered': 792,\n",
       " 'goodno': 793,\n",
       " 'upgrading': 794,\n",
       " 'visible': 795,\n",
       " 'win': 796,\n",
       " 'quickly': 797,\n",
       " 'turning': 798,\n",
       " 'credit': 799,\n",
       " 'providing': 800,\n",
       " 'item': 801,\n",
       " 'consumption': 802,\n",
       " 'carry': 803,\n",
       " 'gamers': 804,\n",
       " 'noticed': 805,\n",
       " 'mobile': 806,\n",
       " 'gave': 807,\n",
       " 'geforce': 808,\n",
       " 'processors': 809,\n",
       " 'g': 810,\n",
       " 'drop': 811,\n",
       " 'reaching': 812,\n",
       " 'lightweight': 813,\n",
       " 'plugged': 814,\n",
       " 'disappoint': 815,\n",
       " 'panel': 816,\n",
       " 'recently': 817,\n",
       " 'marks': 818,\n",
       " 'percent': 819,\n",
       " 'policy': 820,\n",
       " 'adapter': 821,\n",
       " 'note': 822,\n",
       " 'rounder': 823,\n",
       " 'yrs': 824,\n",
       " 'close': 825,\n",
       " 'terrible': 826,\n",
       " 'wrost': 827,\n",
       " 'impressive': 828,\n",
       " 'checked': 829,\n",
       " 'offline': 830,\n",
       " 'dull': 831,\n",
       " 'current': 832,\n",
       " 'upgradable': 833,\n",
       " 'brought': 834,\n",
       " 'python': 835,\n",
       " 'next': 836,\n",
       " 'invest': 837,\n",
       " 'wasnt': 838,\n",
       " 'making': 839,\n",
       " 'casual': 840,\n",
       " 'damaged': 841,\n",
       " 'opinion': 842,\n",
       " 'beautiful': 843,\n",
       " 'saver': 844,\n",
       " 'slots': 845,\n",
       " 'post': 846,\n",
       " 'colors': 847,\n",
       " 'space': 848,\n",
       " 'board': 849,\n",
       " 'batter': 850,\n",
       " 'st': 851,\n",
       " 'ago': 852,\n",
       " 'ya': 853,\n",
       " 'mostly': 854,\n",
       " 'weak': 855,\n",
       " 'show': 856,\n",
       " 'mentioned': 857,\n",
       " 'similar': 858,\n",
       " 'fix': 859,\n",
       " 'autocad': 860,\n",
       " 'stop': 861,\n",
       " 'centre': 862,\n",
       " 'clean': 863,\n",
       " 'updated': 864,\n",
       " 'errors': 865,\n",
       " 'ghz': 866,\n",
       " 'engineering': 867,\n",
       " 'feeling': 868,\n",
       " 'youll': 869,\n",
       " 'whr': 870,\n",
       " 'sturdy': 871,\n",
       " 'error': 872,\n",
       " 'limit': 873,\n",
       " 'loose': 874,\n",
       " 'fact': 875,\n",
       " 'hand': 876,\n",
       " 'confused': 877,\n",
       " 'feedback': 878,\n",
       " 'professional': 879,\n",
       " 'penny': 880,\n",
       " 'gonna': 881,\n",
       " 'prefer': 882,\n",
       " 'blinking': 883,\n",
       " 'research': 884,\n",
       " 'hold': 885,\n",
       " 'details': 886,\n",
       " 'csgo': 887,\n",
       " 'issuei': 888,\n",
       " 'safe': 889,\n",
       " 'placed': 890,\n",
       " 'finish': 891,\n",
       " 'trying': 892,\n",
       " 'zero': 893,\n",
       " 'fully': 894,\n",
       " 'past': 895,\n",
       " 'loving': 896,\n",
       " 'soft': 897,\n",
       " 'photoshop': 898,\n",
       " 'later': 899,\n",
       " 'variant': 900,\n",
       " 'epic': 901,\n",
       " 'gf': 902,\n",
       " 'star': 903,\n",
       " 'heated': 904,\n",
       " 'request': 905,\n",
       " 'antivirus': 906,\n",
       " 'blowing': 907,\n",
       " 'gamming': 908,\n",
       " 'responding': 909,\n",
       " 'restart': 910,\n",
       " 'eyes': 911,\n",
       " 'turns': 912,\n",
       " 'signal': 913,\n",
       " 'reading': 914,\n",
       " 'froze': 915,\n",
       " 'android': 916,\n",
       " 'ur': 917,\n",
       " 'output': 918,\n",
       " 'bottom': 919,\n",
       " 'hardcore': 920,\n",
       " 'along': 921,\n",
       " 'letters': 922,\n",
       " 'overheating': 923,\n",
       " 'applications': 924,\n",
       " 'frequency': 925,\n",
       " 'our': 926,\n",
       " 'further': 927,\n",
       " 'learn': 928,\n",
       " 'response': 929,\n",
       " 'chip': 930,\n",
       " 'complaints': 931,\n",
       " 'laptopbut': 932,\n",
       " 'guess': 933,\n",
       " 'damn': 934,\n",
       " 'resolve': 935,\n",
       " 'related': 936,\n",
       " 'blue': 937,\n",
       " 'socket': 938,\n",
       " 'drained': 939,\n",
       " 'bulky': 940,\n",
       " 'suitable': 941,\n",
       " 'passwords': 942,\n",
       " 'thin': 943,\n",
       " 'offers': 944,\n",
       " 'increase': 945,\n",
       " 'dual': 946,\n",
       " 'movie': 947,\n",
       " 'known': 948,\n",
       " 'manage': 949,\n",
       " 'hd': 950,\n",
       " 'pubg': 951,\n",
       " 'sign': 952,\n",
       " 'ill': 953,\n",
       " 'beat': 954,\n",
       " 'huge': 955,\n",
       " 'app': 956,\n",
       " 'coz': 957,\n",
       " 'including': 958,\n",
       " 'nyc': 959,\n",
       " 'impression': 960,\n",
       " 'charged': 961,\n",
       " 'listen': 962,\n",
       " 'tgp': 963,\n",
       " 'fastest': 964,\n",
       " 'useless': 965,\n",
       " 'reasonable': 966,\n",
       " 'ultimate': 967,\n",
       " 'aspire': 968,\n",
       " 'temperatures': 969,\n",
       " 'needed': 970,\n",
       " 'degrees': 971,\n",
       " 'models': 972,\n",
       " 'rather': 973,\n",
       " 'pls': 974,\n",
       " 'sata': 975,\n",
       " 'indicators': 976,\n",
       " 'lp': 977,\n",
       " 'colours': 978,\n",
       " 'lock': 979,\n",
       " 'piece': 980,\n",
       " 'matt': 981,\n",
       " 'delay': 982,\n",
       " 'preinstalled': 983,\n",
       " 'included': 984,\n",
       " 'hope': 985,\n",
       " 'package': 986,\n",
       " 'added': 987,\n",
       " 'okayish': 988,\n",
       " 'required': 989,\n",
       " 'drive': 990,\n",
       " 'heard': 991,\n",
       " 'hot': 992,\n",
       " 'courier': 993,\n",
       " 'nearest': 994,\n",
       " 'bye': 995,\n",
       " 'paid': 996,\n",
       " 'turbo': 997,\n",
       " 'inches': 998,\n",
       " 'explore': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.key_to_index #This gives word with its index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba27e8fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31217515"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"battery\",\"bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9602a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49771312"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(\"battery\",\"good\") #The word battery has more similarity with the word good than bad.We can \n",
    "#come up with multiple other insigths through this model identifying which word is closer to positive sentiment \n",
    "#and which to negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d3ad4a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4134"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.wv) #Vocabulary length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44381559",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 12:38:00,426 : INFO : reading file Reviews.csv...this may take a while\n",
      "2023-03-23 12:38:00,430 : INFO : read 0 reviews\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[94,\n",
       " 105,\n",
       " 144,\n",
       " 1076,\n",
       " 9,\n",
       " 1328,\n",
       " 305,\n",
       " 383,\n",
       " 820,\n",
       " 144,\n",
       " 572,\n",
       " 424,\n",
       " 2,\n",
       " 16,\n",
       " 139,\n",
       " 812,\n",
       " 49,\n",
       " 1300,\n",
       " 9,\n",
       " 994,\n",
       " 443,\n",
       " 386,\n",
       " 141,\n",
       " 9,\n",
       " 1147,\n",
       " 557,\n",
       " 1423,\n",
       " 5,\n",
       " 812,\n",
       " 2,\n",
       " 443,\n",
       " 187,\n",
       " 87,\n",
       " 532,\n",
       " 14,\n",
       " 640,\n",
       " 1372,\n",
       " 9,\n",
       " 1369,\n",
       " 2,\n",
       " 1364,\n",
       " 686,\n",
       " 2,\n",
       " 16,\n",
       " 7,\n",
       " 38,\n",
       " 46,\n",
       " 360,\n",
       " 14,\n",
       " 44,\n",
       " 5,\n",
       " 29,\n",
       " 80,\n",
       " 16,\n",
       " 220,\n",
       " 595,\n",
       " 26,\n",
       " 12,\n",
       " 59,\n",
       " 649,\n",
       " 72,\n",
       " 7,\n",
       " 5,\n",
       " 41,\n",
       " 15,\n",
       " 39,\n",
       " 1357,\n",
       " 447,\n",
       " 13,\n",
       " 1394,\n",
       " 40,\n",
       " 8,\n",
       " 424,\n",
       " 500,\n",
       " 16,\n",
       " 436,\n",
       " 69,\n",
       " 131,\n",
       " 212,\n",
       " 9,\n",
       " 104,\n",
       " 49,\n",
       " 709,\n",
       " 1,\n",
       " 46,\n",
       " 69,\n",
       " 679,\n",
       " 118,\n",
       " 6,\n",
       " 16,\n",
       " 1030,\n",
       " 8,\n",
       " 834,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 717,\n",
       " 25,\n",
       " 38,\n",
       " 153,\n",
       " 1287,\n",
       " 1288,\n",
       " 689,\n",
       " 1290,\n",
       " 508,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 21,\n",
       " 48,\n",
       " 13,\n",
       " 6,\n",
       " 219,\n",
       " 1,\n",
       " 6,\n",
       " 401,\n",
       " 569,\n",
       " 368,\n",
       " 2,\n",
       " 21,\n",
       " 1274,\n",
       " 78,\n",
       " 1,\n",
       " 432,\n",
       " 0,\n",
       " 41,\n",
       " 1271,\n",
       " 86,\n",
       " 1,\n",
       " 397,\n",
       " 1253,\n",
       " 610,\n",
       " 17,\n",
       " 1258,\n",
       " 0,\n",
       " 1259,\n",
       " 8,\n",
       " 280,\n",
       " 63,\n",
       " 372,\n",
       " 888,\n",
       " 531,\n",
       " 1,\n",
       " 72,\n",
       " 345,\n",
       " 1264,\n",
       " 7,\n",
       " 89,\n",
       " 43,\n",
       " 210,\n",
       " 56,\n",
       " 575,\n",
       " 74,\n",
       " 61,\n",
       " 170,\n",
       " 1294,\n",
       " 508,\n",
       " 90,\n",
       " 196,\n",
       " 100,\n",
       " 1315,\n",
       " 30,\n",
       " 0,\n",
       " 10,\n",
       " 60,\n",
       " 103,\n",
       " 1421,\n",
       " 104,\n",
       " 14,\n",
       " 464,\n",
       " 255,\n",
       " 28,\n",
       " 6,\n",
       " 25,\n",
       " 41,\n",
       " 747,\n",
       " 128,\n",
       " 1390,\n",
       " 1,\n",
       " 50,\n",
       " 5,\n",
       " 157,\n",
       " 902,\n",
       " 20,\n",
       " 110,\n",
       " 74,\n",
       " 132,\n",
       " 187,\n",
       " 368,\n",
       " 33,\n",
       " 144,\n",
       " 1,\n",
       " 43,\n",
       " 6,\n",
       " 3,\n",
       " 216,\n",
       " 0,\n",
       " 10,\n",
       " 1368,\n",
       " 191,\n",
       " 56,\n",
       " 1,\n",
       " 832,\n",
       " 56,\n",
       " 601,\n",
       " 80,\n",
       " 16,\n",
       " 52,\n",
       " 37,\n",
       " 126,\n",
       " 12,\n",
       " 4,\n",
       " 94,\n",
       " 11,\n",
       " 42,\n",
       " 212,\n",
       " 2,\n",
       " 351,\n",
       " 0,\n",
       " 12,\n",
       " 59,\n",
       " 52,\n",
       " 37,\n",
       " 100,\n",
       " 191,\n",
       " 7,\n",
       " 12,\n",
       " 59,\n",
       " 270,\n",
       " 1375,\n",
       " 320,\n",
       " 3,\n",
       " 394,\n",
       " 140,\n",
       " 87,\n",
       " 82,\n",
       " 1,\n",
       " 422,\n",
       " 319,\n",
       " 230,\n",
       " 883,\n",
       " 63,\n",
       " 1,\n",
       " 249,\n",
       " 604,\n",
       " 1,\n",
       " 444,\n",
       " 124,\n",
       " 221,\n",
       " 12,\n",
       " 1044,\n",
       " 46,\n",
       " 275,\n",
       " 0,\n",
       " 790,\n",
       " 49,\n",
       " 1633,\n",
       " 393,\n",
       " 9,\n",
       " 1385,\n",
       " 443,\n",
       " 2426,\n",
       " 2420,\n",
       " 2440,\n",
       " 1208,\n",
       " 67,\n",
       " 443,\n",
       " 1037,\n",
       " 767,\n",
       " 144,\n",
       " 893,\n",
       " 818,\n",
       " 241,\n",
       " 17,\n",
       " 103,\n",
       " 80,\n",
       " 18,\n",
       " 220,\n",
       " 77,\n",
       " 1,\n",
       " 477,\n",
       " 0,\n",
       " 93,\n",
       " 60,\n",
       " 143,\n",
       " 683,\n",
       " 71,\n",
       " 1,\n",
       " 688,\n",
       " 577,\n",
       " 16,\n",
       " 0,\n",
       " 12,\n",
       " 59,\n",
       " 10,\n",
       " 55,\n",
       " 96,\n",
       " 942,\n",
       " 447,\n",
       " 789,\n",
       " 184,\n",
       " 952,\n",
       " 13,\n",
       " 901,\n",
       " 169,\n",
       " 35,\n",
       " 289,\n",
       " 865,\n",
       " 13,\n",
       " 6,\n",
       " 405,\n",
       " 80,\n",
       " 52,\n",
       " 37,\n",
       " 2,\n",
       " 163,\n",
       " 24,\n",
       " 0,\n",
       " 10,\n",
       " 55,\n",
       " 77,\n",
       " 0,\n",
       " 434,\n",
       " 61,\n",
       " 14,\n",
       " 806,\n",
       " 672,\n",
       " 163,\n",
       " 1440,\n",
       " 1,\n",
       " 12,\n",
       " 35,\n",
       " 4,\n",
       " 11,\n",
       " 30,\n",
       " 0,\n",
       " 80,\n",
       " 181,\n",
       " 16,\n",
       " 52,\n",
       " 37,\n",
       " 128,\n",
       " 29,\n",
       " 0,\n",
       " 32,\n",
       " 361,\n",
       " 1,\n",
       " 322,\n",
       " 12,\n",
       " 59,\n",
       " 827,\n",
       " 3,\n",
       " 11,\n",
       " 172,\n",
       " 32,\n",
       " 146,\n",
       " 1358,\n",
       " 71,\n",
       " 42,\n",
       " 82,\n",
       " 1,\n",
       " 1436,\n",
       " 238,\n",
       " 119,\n",
       " 1429,\n",
       " 1433,\n",
       " 322,\n",
       " 737,\n",
       " 7,\n",
       " 66,\n",
       " 358,\n",
       " 9,\n",
       " 1437,\n",
       " 69,\n",
       " 61,\n",
       " 1182,\n",
       " 44,\n",
       " 47,\n",
       " 22,\n",
       " 37,\n",
       " 27,\n",
       " 799,\n",
       " 217,\n",
       " 810,\n",
       " 1004,\n",
       " 0,\n",
       " 12,\n",
       " 732,\n",
       " 9,\n",
       " 7,\n",
       " 20,\n",
       " 119,\n",
       " 26,\n",
       " 11,\n",
       " 939,\n",
       " 159,\n",
       " 99,\n",
       " 108,\n",
       " 1,\n",
       " 113,\n",
       " 56,\n",
       " 48,\n",
       " 79,\n",
       " 243,\n",
       " 326,\n",
       " 32,\n",
       " 36,\n",
       " 48,\n",
       " 79,\n",
       " 243,\n",
       " 1,\n",
       " 48,\n",
       " 680,\n",
       " 243,\n",
       " 8,\n",
       " 274,\n",
       " 20,\n",
       " 12,\n",
       " 44,\n",
       " 5,\n",
       " 29,\n",
       " 11,\n",
       " 1561,\n",
       " 0,\n",
       " 80,\n",
       " 7,\n",
       " 180,\n",
       " 338,\n",
       " 193,\n",
       " 262,\n",
       " 52,\n",
       " 995,\n",
       " 6,\n",
       " 48,\n",
       " 459,\n",
       " 345,\n",
       " 1559,\n",
       " 128,\n",
       " 29,\n",
       " 52,\n",
       " 37,\n",
       " 2,\n",
       " 80,\n",
       " 144,\n",
       " 1,\n",
       " 16,\n",
       " 43,\n",
       " 80,\n",
       " 208,\n",
       " 133,\n",
       " 558,\n",
       " 12,\n",
       " 288,\n",
       " 13,\n",
       " 1352,\n",
       " 36,\n",
       " 9,\n",
       " 996,\n",
       " 139,\n",
       " 1344,\n",
       " 206,\n",
       " 320,\n",
       " 830,\n",
       " 189,\n",
       " 288,\n",
       " 19,\n",
       " 408,\n",
       " 17,\n",
       " 379,\n",
       " 11,\n",
       " 0,\n",
       " 73,\n",
       " 521,\n",
       " 12,\n",
       " 87,\n",
       " 180,\n",
       " 193,\n",
       " 2,\n",
       " 1097,\n",
       " 216,\n",
       " 72,\n",
       " 1603,\n",
       " 342,\n",
       " 82,\n",
       " 17,\n",
       " 381,\n",
       " 12,\n",
       " 1599,\n",
       " 6,\n",
       " 16,\n",
       " 28,\n",
       " 39,\n",
       " 42,\n",
       " 48,\n",
       " 212,\n",
       " 7,\n",
       " 703,\n",
       " 59,\n",
       " 11,\n",
       " 203,\n",
       " 109,\n",
       " 0,\n",
       " 10,\n",
       " 1338,\n",
       " 771,\n",
       " 62,\n",
       " 104,\n",
       " 601,\n",
       " 11,\n",
       " 1326,\n",
       " 1057,\n",
       " 1325,\n",
       " 19,\n",
       " 6,\n",
       " 356,\n",
       " 16,\n",
       " 67,\n",
       " 1329,\n",
       " 111,\n",
       " 108,\n",
       " 20,\n",
       " 72,\n",
       " 1145,\n",
       " 10,\n",
       " 1332,\n",
       " 8,\n",
       " 167,\n",
       " 2,\n",
       " 169,\n",
       " 52,\n",
       " 592,\n",
       " 45,\n",
       " 52,\n",
       " 37,\n",
       " 6,\n",
       " 16,\n",
       " 27,\n",
       " 83,\n",
       " 12,\n",
       " 204,\n",
       " 11,\n",
       " 1,\n",
       " 163,\n",
       " 241,\n",
       " 440,\n",
       " 10,\n",
       " 94,\n",
       " 24,\n",
       " 3,\n",
       " 0,\n",
       " 500,\n",
       " 77,\n",
       " 0,\n",
       " 1592,\n",
       " 1,\n",
       " 221,\n",
       " 24,\n",
       " 0,\n",
       " 464,\n",
       " 8,\n",
       " 1595,\n",
       " 5,\n",
       " 322,\n",
       " 27,\n",
       " 2,\n",
       " 210,\n",
       " 129,\n",
       " 8,\n",
       " 72,\n",
       " 2,\n",
       " 3,\n",
       " 2707,\n",
       " 2717,\n",
       " 15,\n",
       " 265,\n",
       " 145,\n",
       " 46,\n",
       " 197,\n",
       " 83,\n",
       " 341,\n",
       " 144,\n",
       " 0,\n",
       " 87,\n",
       " 464,\n",
       " 61,\n",
       " 2,\n",
       " 3,\n",
       " 11,\n",
       " 36,\n",
       " 762,\n",
       " 56,\n",
       " 230,\n",
       " 205,\n",
       " 961,\n",
       " 67,\n",
       " 13,\n",
       " 153,\n",
       " 61,\n",
       " 535,\n",
       " 1,\n",
       " 391,\n",
       " 67,\n",
       " 9,\n",
       " 893,\n",
       " 2699,\n",
       " 535,\n",
       " 13,\n",
       " 2700,\n",
       " 108,\n",
       " 3,\n",
       " 187,\n",
       " 628,\n",
       " 27,\n",
       " 8,\n",
       " 712,\n",
       " 6,\n",
       " 114,\n",
       " 42,\n",
       " 82,\n",
       " 17,\n",
       " 68,\n",
       " 1,\n",
       " 8,\n",
       " 856,\n",
       " 45,\n",
       " 79,\n",
       " 0,\n",
       " 284,\n",
       " 140,\n",
       " 1,\n",
       " 1158,\n",
       " 17,\n",
       " 300,\n",
       " 71,\n",
       " 1,\n",
       " 11,\n",
       " 2756,\n",
       " 70,\n",
       " 2,\n",
       " 96,\n",
       " 17,\n",
       " 65,\n",
       " 333,\n",
       " 968,\n",
       " 3,\n",
       " 5,\n",
       " 165,\n",
       " 38,\n",
       " 55,\n",
       " 9,\n",
       " 2731,\n",
       " 19,\n",
       " 49,\n",
       " 3,\n",
       " 89,\n",
       " 90,\n",
       " 762,\n",
       " 11,\n",
       " 124,\n",
       " 520,\n",
       " 191,\n",
       " 1,\n",
       " 2734,\n",
       " 0,\n",
       " 232,\n",
       " 2737,\n",
       " 603,\n",
       " 49,\n",
       " 2740,\n",
       " 1,\n",
       " 13,\n",
       " 2725,\n",
       " 9,\n",
       " 6,\n",
       " 7,\n",
       " 89,\n",
       " 226,\n",
       " 5,\n",
       " 2625,\n",
       " 55,\n",
       " 60,\n",
       " 310,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 180,\n",
       " 19,\n",
       " 8,\n",
       " 248,\n",
       " 247,\n",
       " 395,\n",
       " 930,\n",
       " 9,\n",
       " 49,\n",
       " 2635,\n",
       " 7,\n",
       " 187,\n",
       " 591,\n",
       " 156,\n",
       " 28,\n",
       " 39,\n",
       " 260,\n",
       " 8,\n",
       " 394,\n",
       " 472,\n",
       " 289,\n",
       " 924,\n",
       " 145,\n",
       " 2640,\n",
       " 118,\n",
       " 543,\n",
       " 7,\n",
       " 31,\n",
       " 591,\n",
       " 661,\n",
       " 49,\n",
       " 133,\n",
       " 2633,\n",
       " 7,\n",
       " 0,\n",
       " 249,\n",
       " 12,\n",
       " 115,\n",
       " 1,\n",
       " 2610,\n",
       " 3,\n",
       " 532,\n",
       " 8,\n",
       " 137,\n",
       " 629,\n",
       " 925,\n",
       " 866,\n",
       " 15,\n",
       " 83,\n",
       " 776,\n",
       " 137,\n",
       " 629,\n",
       " 925,\n",
       " 866,\n",
       " 2612,\n",
       " 925,\n",
       " 15,\n",
       " 3,\n",
       " 0,\n",
       " 12,\n",
       " 368,\n",
       " 155,\n",
       " 466,\n",
       " 12,\n",
       " 270,\n",
       " 59,\n",
       " 2666,\n",
       " 140,\n",
       " 5,\n",
       " 165,\n",
       " 330,\n",
       " 12,\n",
       " 59,\n",
       " 1,\n",
       " 2669,\n",
       " 100,\n",
       " 2672,\n",
       " 17,\n",
       " 55,\n",
       " 24,\n",
       " 67,\n",
       " 333,\n",
       " 80,\n",
       " 3,\n",
       " 572,\n",
       " 220,\n",
       " 140,\n",
       " 441,\n",
       " 12,\n",
       " 65,\n",
       " 2673,\n",
       " 48,\n",
       " 165,\n",
       " 15,\n",
       " 1627,\n",
       " 849,\n",
       " 71,\n",
       " 336,\n",
       " 7,\n",
       " 38,\n",
       " 12,\n",
       " 4,\n",
       " 181,\n",
       " 17,\n",
       " 29,\n",
       " 12,\n",
       " 40,\n",
       " 207,\n",
       " 26,\n",
       " 2647,\n",
       " 2445,\n",
       " 12,\n",
       " 59,\n",
       " 242,\n",
       " 8,\n",
       " 38,\n",
       " 320,\n",
       " 6,\n",
       " 3,\n",
       " 82,\n",
       " 203,\n",
       " 32,\n",
       " 15,\n",
       " 230,\n",
       " 1797,\n",
       " 199,\n",
       " 77,\n",
       " 27,\n",
       " 2,\n",
       " 26,\n",
       " 473,\n",
       " 669,\n",
       " 199,\n",
       " 2653,\n",
       " 37,\n",
       " 28,\n",
       " 99,\n",
       " 379,\n",
       " 2652,\n",
       " 2648,\n",
       " 2,\n",
       " 1189,\n",
       " 43,\n",
       " 56,\n",
       " 0,\n",
       " 210,\n",
       " 35,\n",
       " 262,\n",
       " 52,\n",
       " 139,\n",
       " 28,\n",
       " 99,\n",
       " 379,\n",
       " 11,\n",
       " 30,\n",
       " 0,\n",
       " 10,\n",
       " 55,\n",
       " 11,\n",
       " 0,\n",
       " 117,\n",
       " 1,\n",
       " 26,\n",
       " 0,\n",
       " 43,\n",
       " 117,\n",
       " 15,\n",
       " 18,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 275,\n",
       " 43,\n",
       " 117,\n",
       " 64,\n",
       " 0,\n",
       " 14,\n",
       " 117,\n",
       " 3,\n",
       " 903,\n",
       " 957,\n",
       " 17,\n",
       " 2,\n",
       " 11,\n",
       " 30,\n",
       " 78,\n",
       " 12,\n",
       " 1174,\n",
       " 226,\n",
       " 34,\n",
       " 80,\n",
       " 2668,\n",
       " 87,\n",
       " 49,\n",
       " 672,\n",
       " 89,\n",
       " 4,\n",
       " 77,\n",
       " 69,\n",
       " 61,\n",
       " 6,\n",
       " 3,\n",
       " 11,\n",
       " 391,\n",
       " 70,\n",
       " 7,\n",
       " 38,\n",
       " 49,\n",
       " 80,\n",
       " 96,\n",
       " 17,\n",
       " 6,\n",
       " 16,\n",
       " 2,\n",
       " 83,\n",
       " 1073,\n",
       " 38,\n",
       " 12,\n",
       " 1754,\n",
       " 9,\n",
       " 341,\n",
       " 101,\n",
       " 189,\n",
       " 2644,\n",
       " 411,\n",
       " 124,\n",
       " 189,\n",
       " 2603,\n",
       " 48,\n",
       " 1486,\n",
       " 669,\n",
       " 46,\n",
       " 2620,\n",
       " 1761,\n",
       " 32,\n",
       " 1488,\n",
       " 45,\n",
       " 1486,\n",
       " 13,\n",
       " 48,\n",
       " 1169,\n",
       " 55,\n",
       " 2,\n",
       " 163,\n",
       " 24,\n",
       " 0,\n",
       " 10,\n",
       " 55,\n",
       " 77,\n",
       " 0,\n",
       " 434,\n",
       " 61,\n",
       " 14,\n",
       " 806,\n",
       " 672,\n",
       " 163,\n",
       " 1440,\n",
       " 1,\n",
       " 12,\n",
       " 35,\n",
       " 4,\n",
       " 11,\n",
       " 30,\n",
       " 0,\n",
       " 80,\n",
       " 181,\n",
       " 16,\n",
       " 52,\n",
       " 37,\n",
       " 128,\n",
       " 29,\n",
       " 0,\n",
       " 32,\n",
       " 361,\n",
       " 1,\n",
       " 322,\n",
       " 12,\n",
       " 59,\n",
       " 827,\n",
       " 3,\n",
       " 11,\n",
       " 172,\n",
       " 32,\n",
       " 146,\n",
       " 1358,\n",
       " 71,\n",
       " 42,\n",
       " 82,\n",
       " 1,\n",
       " 1436,\n",
       " 238,\n",
       " 119,\n",
       " 1429,\n",
       " 1433,\n",
       " 322,\n",
       " 737,\n",
       " 7,\n",
       " 66,\n",
       " 358,\n",
       " 9,\n",
       " 1437,\n",
       " 69,\n",
       " 61,\n",
       " 1182,\n",
       " 44,\n",
       " 47,\n",
       " 22,\n",
       " 37,\n",
       " 27,\n",
       " 799,\n",
       " 217,\n",
       " 810,\n",
       " 1004,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[model.wv.key_to_index[token] if token in model.wv.key_to_index else 4134 for r_tokens in laptop_reader for token in r_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bea1c1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e052c946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(laptop['Sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c2e54f",
   "metadata": {},
   "source": [
    "# Combining with pre trained word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f468f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 12:38:14,422 : INFO : loading projection weights from /Users/sheetalrajgure/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\n",
      "2023-03-23 12:39:18,460 : INFO : KeyedVectors lifecycle event {'msg': 'loaded (3000000, 300) matrix of type float32 from /Users/sheetalrajgure/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz', 'binary': True, 'encoding': 'utf8', 'datetime': '2023-03-23T12:39:18.454316', 'gensim': '4.3.1', 'python': '3.9.7 (default, Sep 16 2021, 08:50:36) \\n[Clang 10.0.0 ]', 'platform': 'macOS-10.16-x86_64-i386-64bit', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gensim.downloader as api\n",
    "\n",
    "# Load pre-trained vectors\n",
    "pretrained_wv = api.load('word2vec-google-news-300')\n",
    "\n",
    "# Get custom vectors from Word2Vec model\n",
    "custom_wv = model.wv\n",
    "\n",
    "# Define the combined vector size\n",
    "combined_size = custom_wv.vector_size + pretrained_wv.vector_size\n",
    "\n",
    "# Create a matrix of zeros with shape (vocab_size, combined_size)\n",
    "combined_wv = np.zeros((len(custom_wv.key_to_index) + len(pretrained_wv.key_to_index), combined_size))\n",
    "\n",
    "# Copy custom wv vectors into combined wv\n",
    "for i, word in enumerate(custom_wv.index_to_key):\n",
    "    combined_wv[i] = np.concatenate([custom_wv[word], np.zeros(pretrained_wv.vector_size)])\n",
    "\n",
    "# Copy pretrained wv vectors into combined wv\n",
    "j = len(custom_wv.key_to_index)\n",
    "for i, word in enumerate(pretrained_wv.index_to_key):\n",
    "    if word not in custom_wv:\n",
    "        combined_wv[j] = np.concatenate([np.zeros(custom_wv.vector_size), pretrained_wv[word]])\n",
    "        j += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae5335d",
   "metadata": {},
   "source": [
    "# Mean vector of reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7e0b6f",
   "metadata": {},
   "source": [
    "We have created word embeddings, now let us create embeddings for a review\n",
    "We would take average of each word's vector in a review to get the vector of the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc7653e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 12:40:58,300 : INFO : reading file Reviews.csv...this may take a while\n",
      "2023-03-23 12:40:58,312 : INFO : read 0 reviews\n"
     ]
    }
   ],
   "source": [
    "#Mean vector of reviews with custom word2vec\n",
    "import numpy as np\n",
    "\n",
    "reviews_vector = []\n",
    "for r in laptop_reader:\n",
    "    vectors = [model.wv[token] for token in r if token in model.wv]\n",
    "    if vectors:\n",
    "        e = np.mean(vectors, axis=0)\n",
    "        reviews_vector.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4981b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 12:41:00,395 : INFO : reading file Reviews.csv...this may take a while\n",
      "2023-03-23 12:41:00,399 : INFO : read 0 reviews\n"
     ]
    }
   ],
   "source": [
    "#Mean vector of reviews with pretrained word2vec\n",
    "pretrained_reviews_vector = []\n",
    "for r in laptop_reader:\n",
    "    vectors = [pretrained_wv[token] for token in r if token in pretrained_wv]\n",
    "    if vectors:\n",
    "        e = np.mean(vectors, axis=0)\n",
    "        pretrained_reviews_vector.append(e)\n",
    "    else:\n",
    "        e = np.zeros(vectors)\n",
    "        pretrained_reviews_vector.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efabe30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the mean vectors -- in a vector of 100 + 300 = 400 size\n",
    "# For the scope of this project, we use mean vectors of only custom embeddings in the next steps\n",
    "# However the same steps could be extended using the combined vector of size 400, we kept this as future analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9fc63e",
   "metadata": {},
   "source": [
    "# Sentiment Analysis using Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe4fa89",
   "metadata": {},
   "source": [
    "Train test split for classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f5a07caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = reviews_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "47a2704f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = laptop['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a84ecf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train , x_test , y_train , y_test = train_test_split(x, y, test_size= 0.20 , random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "264f48fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a9cb71f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.84\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(x_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "658699fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[311   5  72]\n",
      " [ 39  26  64]\n",
      " [ 34   4 819]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "23115c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54b54da",
   "metadata": {},
   "source": [
    "# Sentiment Analysis using Recurrent Neural Network (RNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9201867b",
   "metadata": {},
   "source": [
    "Replacing Sentiments to integers as the model requires it later (for the target variables to not be in string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "25702c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(laptop['Sentiment'].replace({'positive': 1, 'negative': 0, 'neutral': 2, 'Negative': 0}).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcbc407",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1155dc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5496 5496 1373 1373\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the data\n",
    "seed = 4803\n",
    "rng = np.random.RandomState(seed)\n",
    "samples = laptop['Summary'].values\n",
    "labels = laptop['Sentiment'].replace({'positive': 1, 'negative': 0, 'neutral': 2, 'Negative': 0}).values\n",
    "rng.shuffle(samples)\n",
    "rng = np.random.RandomState(seed)\n",
    "rng.shuffle(labels)\n",
    "\n",
    "# Extract a training & validation split\n",
    "test_split = 0.2\n",
    "num_test_samples = int(test_split * len(samples))\n",
    "train_samples = samples[:-num_test_samples]\n",
    "test_samples = samples[-num_test_samples:]\n",
    "train_labels = labels[:-num_test_samples]\n",
    "test_labels = labels[-num_test_samples:]\n",
    "\n",
    "print(len(train_samples), len(train_labels), len(test_samples), len(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05aeda4",
   "metadata": {},
   "source": [
    "# Create a vocabulary index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cb734f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 12:45:00.521592: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-23 12:45:26.575215: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "import tensorflow\n",
    "\n",
    "vectorizer = TextVectorization(max_tokens=20000, output_sequence_length=200)\n",
    "text_ds = tensorflow.data.Dataset.from_tensor_slices(train_samples).batch(128)\n",
    "vectorizer.adapt(text_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e76f42d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = vectorizer.get_vocabulary()\n",
    "word_index = dict(zip(voc, range(len(voc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "55b67340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4870, 4870)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(voc), len(word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa372d7",
   "metadata": {},
   "source": [
    "# Embedding_matrix for RNN enbedding layer\n",
    "Preparing a corresponding embedding matrix that we can use in a Keras Embedding layer. It's a simple NumPy matrix where entry at index i is the pre-trained vector for the word of index i in our vectorizer's vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6be5cf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 4026 words (844 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(word_index) + 2\n",
    "embedding_dim = model.wv.vector_size\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if word in model.wv.key_to_index:\n",
    "        embedding_vector = model.wv.get_vector(word)\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\" - out of vocabulary\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bee683",
   "metadata": {},
   "source": [
    "# Train Test Samples assignment to a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9254a442",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = vectorizer(np.array([[s] for s in train_samples])).numpy()\n",
    "x_test = vectorizer(np.array([[s] for s in test_samples])).numpy()\n",
    "\n",
    "y_train = np.array(train_labels)\n",
    "y_test = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6314d9f7",
   "metadata": {},
   "source": [
    "# Building the RNN Model\n",
    "1 input layer, 2 hidden layers (including one Embedding Layer and one LSTM layer) and one output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7599d689",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 100)         487200    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 128)              84480     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 571,809\n",
      "Trainable params: 84,609\n",
      "Non-trainable params: 487,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=False,\n",
    ")\n",
    "\n",
    "#x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
    "x = layers.Bidirectional(layers.LSTM(64))(embedding_layer(inputs))\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model_RNN = keras.Model(inputs, outputs)\n",
    "model_RNN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6713ae0",
   "metadata": {},
   "source": [
    "# Fitting the model to train data and checking the accuracy on test data\n",
    "We have used 2 Epochs, since the dataset is ~600 and we do not require more Epochs..otherwise it will overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "705ab7af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "172/172 [==============================] - 41s 215ms/step - loss: 0.3674 - accuracy: 0.6847 - val_loss: 0.1883 - val_accuracy: 0.7553\n",
      "Epoch 2/2\n",
      "172/172 [==============================] - 36s 207ms/step - loss: 0.1694 - accuracy: 0.7817 - val_loss: 0.1290 - val_accuracy: 0.7844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd1b4446790>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_RNN.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "model_RNN.fit(x_train, y_train, batch_size=32, epochs=2, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6182e987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RNN on test set: 78.2% after 2 Epochs\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of RNN on test set: 78.2% after 2 Epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a6ad31",
   "metadata": {},
   "source": [
    "Neural Networks are better for Sentiment Analysis than Logistic Regression\n",
    "Given a review, we can identify its sentiment and extract its topics using Sentiment Analysis and Topic Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a4f181",
   "metadata": {},
   "source": [
    "# PART 2: TOPIC MODELLING USING LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1751a850",
   "metadata": {},
   "source": [
    "# Step 1: Data Pre-processing\n",
    "Converting the text to lowercase.<br>\n",
    "Apply lemmatization to the words so that the root words of all derived words are used. <br>\n",
    "Remove stop-words <br>\n",
    "Remove words with lengths less than 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bfd07863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'other', 'am', 'hadn', 'it', 'a', 'because', 'been', 'where', 'there', 'his', 'during', 'of', 'our', 'mightn', 'very', 'before', 'them', 'some', 'same', 'will', 'doing', 'after', 'she', 'is', 'as', 'o', 'through', \"you'll\", 'hers', 'has', 'who', 'y', 'most', 'won', 'd', \"doesn't\", \"don't\", 'between', 'on', 'than', 'its', 'he', \"wasn't\", \"hasn't\", \"you'd\", \"isn't\", 'how', 'why', 'and', 'by', \"needn't\", 'have', 'so', 're', 'being', 'both', \"shouldn't\", 'myself', 'the', \"won't\", 'if', 'needn', \"weren't\", 'with', 'at', \"should've\", \"hadn't\", 'yours', 'about', 't', 'are', 'hasn', \"aren't\", 'which', 'm', 'doesn', 'once', 'isn', 'or', 'what', 'does', \"you're\", 'those', \"wouldn't\", 'these', 'while', 'such', 'that', 'again', 'themselves', 'any', 'nor', 'too', 'mustn', \"that'll\", 'into', 'did', 'in', 've', 'your', 'shan', 'itself', 'further', 'yourselves', 'didn', 'haven', \"it's\", \"mustn't\", 'not', 'were', 'my', 'then', 'wasn', 'out', 'aren', 'all', 'here', \"couldn't\", 'couldn', \"she's\", 'him', 'they', 'herself', 'below', 'do', 'when', 'be', 'i', 'ma', 'above', 'off', 'll', 'having', 'ain', 'more', 'an', 'her', 'to', 'ourselves', \"haven't\", 'shouldn', 'theirs', \"mightn't\", 'each', 'their', \"you've\", 'but', 'yourself', 'me', 'should', 'from', 'we', 'can', 'until', 'you', 'was', 'himself', \"didn't\", 'weren', 'now', 'this', 'under', 'had', 'no', 'ours', 'few', 'wouldn', \"shan't\", 'whom'}\n"
     ]
    }
   ],
   "source": [
    "#Checking the stop words we got from nltk library\n",
    "stop_words = {'themselves', 'theirs', 'as', 'yourselves', 'mightn', 'll', 'hers', 'about', \"shouldn't\", \"isn't\", 'doing', \"needn't\", 'needn', 'y', 'himself', 'when', \"didn't\", 'haven', 'our', 'had', 'were', 'which', 'yourself', 'can', 'most', 'or', \"couldn't\", 'be', 'too', 'above', 'before', 'more', 'o', \"you're\", 'we', 'some', 'no', 'isn', 'my', 'after', 'below', 'nor', 'through', 'where', 'ours', 'in', 'its', 'yours', 'them', 've', \"mightn't\", 'wasn', \"should've\", 'hadn', 'wouldn', 'who', 'have', 'so', 'there', 'he', 'here', 'while', 'these', 'is', 'd', 'her', 'it', 'from', 'same', 'his', 'such', 'am', 'having', 'a', 'by', 'during', \"weren't\", \"she's\", 'an', 'off', 'doesn', 'any', 'out', 'but', \"doesn't\", 'this', 'because', 'their', 'myself', \"hadn't\", 'and', 'under', 'that', 'both', 'aren', \"that'll\", 'shan', 'hasn', 'weren', 'been', 'shouldn', 'other', \"wouldn't\", 'how', \"you'll\", \"hasn't\", 'few', 'once', 'mustn', 'him', \"it's\", \"you'd\", 'to', 't', 'each', 'very', 'why', 're', 'further', 'those', 'will', 'into', 'me', 'all', 'then', 'ourselves', 'm', \"aren't\", 'they', 'didn', 'itself', 'your', 'won', 'ain', \"mustn't\", 'being', 'not', 'did', \"won't\", 'of', 'couldn', 'should', \"don't\", 'you', 'with', 'do', 'she', 'the', 'at', 'what', 'now', 'does', 'herself', 'between', 'are', 'if', 'was', \"wasn't\", 'ma', \"haven't\", 'i', 'until', \"shan't\", 'than', 'whom', 'again', 'has', \"you've\", 'on'}\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8ed3ba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Define a function to pre-process the data\n",
    "def clean_text(review):\n",
    "    le=WordNetLemmatizer() ##Lemmatize\n",
    "    word_tokens=word_tokenize(review) ##Splits given sentence into words i.e. tokenize\n",
    "    tokens=[le.lemmatize(w) for w in word_tokens if w not in stop_words and len(w)>1] #Create tokens\n",
    "    cleaned_review=\" \".join(tokens)\n",
    "    return cleaned_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b2044349",
   "metadata": {},
   "outputs": [],
   "source": [
    "laptop['cleaned_review']=laptop['Summary'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "37e89f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductName</th>\n",
       "      <th>Rate</th>\n",
       "      <th>Review</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>cleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASUS TUF Gaming F15 Core i5 10th Gen - (8 GB/5...</td>\n",
       "      <td>1</td>\n",
       "      <td>Horrible</td>\n",
       "      <td>value for money laptop battery backup is low b...</td>\n",
       "      <td>negative</td>\n",
       "      <td>value for money laptop battery backup low that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASUS TUF Gaming F15 Core i5 10th Gen - (8 GB/5...</td>\n",
       "      <td>1</td>\n",
       "      <td>Worthless</td>\n",
       "      <td>best gaming lappy in low price range with good...</td>\n",
       "      <td>negative</td>\n",
       "      <td>best gaming lappy low price range good graphic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS TUF Gaming F15 Core i5 10th Gen - (8 GB/5...</td>\n",
       "      <td>1</td>\n",
       "      <td>Utterly Disappointed</td>\n",
       "      <td>best laptop at this price range pros new ryzen...</td>\n",
       "      <td>negative</td>\n",
       "      <td>best laptop price range pro new ryzen processo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS TUF Gaming F15 Core i5 10th Gen - (8 GB/5...</td>\n",
       "      <td>1</td>\n",
       "      <td>Useless product</td>\n",
       "      <td>delivered without defect and arrived on timebe...</td>\n",
       "      <td>negative</td>\n",
       "      <td>delivered without defect arrived timebest valu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS TUF Gaming F15 Core i5 10th Gen - (8 GB/5...</td>\n",
       "      <td>1</td>\n",
       "      <td>Worthless</td>\n",
       "      <td>this laptop is very nice and good looking perf...</td>\n",
       "      <td>negative</td>\n",
       "      <td>laptop nice good looking performance also good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         ProductName  Rate  \\\n",
       "0  ASUS TUF Gaming F15 Core i5 10th Gen - (8 GB/5...     1   \n",
       "1  ASUS TUF Gaming F15 Core i5 10th Gen - (8 GB/5...     1   \n",
       "2  ASUS TUF Gaming F15 Core i5 10th Gen - (8 GB/5...     1   \n",
       "3  ASUS TUF Gaming F15 Core i5 10th Gen - (8 GB/5...     1   \n",
       "4  ASUS TUF Gaming F15 Core i5 10th Gen - (8 GB/5...     1   \n",
       "\n",
       "                 Review                                            Summary  \\\n",
       "0              Horrible  value for money laptop battery backup is low b...   \n",
       "1             Worthless  best gaming lappy in low price range with good...   \n",
       "2  Utterly Disappointed  best laptop at this price range pros new ryzen...   \n",
       "3       Useless product  delivered without defect and arrived on timebe...   \n",
       "4             Worthless  this laptop is very nice and good looking perf...   \n",
       "\n",
       "  Sentiment                                     cleaned_review  \n",
       "0  negative  value for money laptop battery backup low that...  \n",
       "1  negative     best gaming lappy low price range good graphic  \n",
       "2  negative  best laptop price range pro new ryzen processo...  \n",
       "3  negative  delivered without defect arrived timebest valu...  \n",
       "4  negative     laptop nice good looking performance also good  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptop.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadc0356",
   "metadata": {},
   "source": [
    "# Step 2: Convert each word to a vector form\n",
    "For topic modeling, we would use CountVectorizer <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c46b94ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise the count vectorizer\n",
    "vectorizer = CountVectorizer(analyzer = 'word', ngram_range = (1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7782b7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize a list (for each word to be added in a vectors list)\n",
    "vectors = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2127f47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join the processed data to be vectorised\n",
    "for index, row in laptop['cleaned_review'].to_frame().iterrows():\n",
    "    vectors.append(row['cleaned_review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0fd3f4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now transform each word to a vector form\n",
    "vectorised = vectorizer.fit_transform(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9420e0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vectorised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5b06a6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 22070)\t1\n",
      "  (0, 7812)\t1\n",
      "  (0, 13671)\t1\n",
      "  (0, 11687)\t3\n",
      "  (0, 2701)\t1\n",
      "  (0, 2448)\t1\n",
      "  (0, 13026)\t1\n",
      "  (0, 20673)\t1\n",
      "  (0, 7012)\t1\n",
      "  (0, 8585)\t2\n",
      "  (0, 3417)\t1\n",
      "  (0, 849)\t1\n",
      "  (0, 14539)\t1\n",
      "  (0, 19875)\t1\n",
      "  (0, 8758)\t1\n",
      "  (0, 446)\t1\n",
      "  (0, 19509)\t1\n",
      "  (0, 17519)\t2\n",
      "  (0, 18510)\t1\n",
      "  (0, 21608)\t1\n",
      "  (0, 10738)\t1\n",
      "  (0, 12914)\t1\n",
      "  (0, 21592)\t1\n",
      "  (0, 22074)\t1\n",
      "  (0, 8042)\t1\n",
      "  :\t:\n",
      "  (6867, 8449)\t1\n",
      "  (6867, 331)\t1\n",
      "  (6867, 13967)\t1\n",
      "  (6867, 9604)\t1\n",
      "  (6867, 12389)\t1\n",
      "  (6867, 1243)\t1\n",
      "  (6867, 3425)\t1\n",
      "  (6867, 5410)\t1\n",
      "  (6867, 362)\t1\n",
      "  (6867, 5447)\t1\n",
      "  (6867, 7881)\t1\n",
      "  (6867, 1823)\t1\n",
      "  (6867, 8938)\t1\n",
      "  (6867, 20747)\t1\n",
      "  (6867, 10590)\t1\n",
      "  (6867, 18399)\t1\n",
      "  (6867, 17086)\t1\n",
      "  (6867, 2913)\t1\n",
      "  (6867, 1263)\t1\n",
      "  (6867, 18428)\t1\n",
      "  (6867, 12284)\t1\n",
      "  (6867, 8536)\t1\n",
      "  (6867, 16630)\t1\n",
      "  (6867, 11741)\t1\n",
      "  (6868, 14301)\t1\n"
     ]
    }
   ],
   "source": [
    "print(vectorised)\n",
    "##INTERPRETATION: 1st digit in the tuple is the index of the review / row number, \n",
    "#the second number in the tuple is the number form of words from vocabulary \n",
    "#and the second column is the occurance of that particular word\n",
    "##For example\n",
    "##In row 0 i.e. review 1st, a word whose vector format is 16373 occurs once in the review, \n",
    "##a word whose vector format is 19297 occurs twice in the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6b412923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6869, 23225)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorised.get_shape() ##Just to check the shape, we have 6869 reviews as in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7efc0dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initisalise LDA Model\n",
    "lda_model = LatentDirichletAllocation(n_components = 7, # number of topics\n",
    "                                  random_state = 0,          # random state\n",
    "                                  evaluate_every = -1,      # compute perplexity every n iters, default: Don't\n",
    "                                  n_jobs = -1,              # Use all available CPUs\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "be1490d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/Applications/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/Applications/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/Applications/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to our vectorised\n",
    "output = lda_model.fit_transform(vectorised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "05def089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6869, 7)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Shape = No of reviews x no of clusters\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a3ba86c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The above fit would cluster the reviews in 10 clusters called 'topics'\n",
    "#A document or a review is a mix of multiple topics\n",
    "#We need to find out what is the dominant topic of each review\n",
    "#First of all lets create columns for each topic & dominant topic in our dataframe\n",
    "topic_names = [\"Topic\" + str(i) for i in range(1, lda_model.n_components + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "142309ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with these 10 columns\n",
    "laptop_reviews_topic = pd.DataFrame(np.round(output, 4), columns = topic_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "44b4d765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out the dominant topic for each review\n",
    "dominant_topic = (np.argmax(laptop_reviews_topic.values, axis=1)+1)\n",
    "\n",
    "# Add column to dataframe\n",
    "laptop_reviews_topic['Dominant_topic'] = dominant_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a8291c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic1</th>\n",
       "      <th>Topic2</th>\n",
       "      <th>Topic3</th>\n",
       "      <th>Topic4</th>\n",
       "      <th>Topic5</th>\n",
       "      <th>Topic6</th>\n",
       "      <th>Topic7</th>\n",
       "      <th>Dominant_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7906</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.1962</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.9462</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9828</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.3599</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.5954</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.9386</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6864</th>\n",
       "      <td>0.8883</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.1035</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6865</th>\n",
       "      <td>0.7855</td>\n",
       "      <td>0.0357</td>\n",
       "      <td>0.0358</td>\n",
       "      <td>0.0358</td>\n",
       "      <td>0.0357</td>\n",
       "      <td>0.0357</td>\n",
       "      <td>0.0358</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6866</th>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.8569</td>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.0239</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6867</th>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.9916</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6868</th>\n",
       "      <td>0.0715</td>\n",
       "      <td>0.0716</td>\n",
       "      <td>0.0715</td>\n",
       "      <td>0.5711</td>\n",
       "      <td>0.0715</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>0.0715</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6869 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Topic1  Topic2  Topic3  Topic4  Topic5  Topic6  Topic7  Dominant_topic\n",
       "0     0.7906  0.0027  0.1962  0.0026  0.0026  0.0026  0.0026               1\n",
       "1     0.0090  0.0090  0.0089  0.0089  0.0090  0.0090  0.9462               7\n",
       "2     0.9828  0.0029  0.0029  0.0029  0.0029  0.0029  0.0029               1\n",
       "3     0.0089  0.0089  0.3599  0.0089  0.0089  0.0089  0.5954               7\n",
       "4     0.0102  0.0103  0.0102  0.0103  0.0102  0.0102  0.9386               7\n",
       "...      ...     ...     ...     ...     ...     ...     ...             ...\n",
       "6864  0.8883  0.0016  0.1035  0.0016  0.0016  0.0016  0.0016               1\n",
       "6865  0.7855  0.0357  0.0358  0.0358  0.0357  0.0357  0.0358               1\n",
       "6866  0.0239  0.8569  0.0239  0.0238  0.0238  0.0238  0.0239               2\n",
       "6867  0.0014  0.0014  0.0014  0.0014  0.9916  0.0014  0.0014               5\n",
       "6868  0.0715  0.0716  0.0715  0.5711  0.0715  0.0714  0.0715               4\n",
       "\n",
       "[6869 rows x 8 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the dataframe\n",
    "laptop_reviews_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e6140aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join this to original dataframes with mapping the index\n",
    "laptop = pd.merge(laptop, laptop_reviews_topic, left_index = True, right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "488c4ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductName</th>\n",
       "      <th>Rate</th>\n",
       "      <th>Review</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>Topic1</th>\n",
       "      <th>Topic2</th>\n",
       "      <th>Topic3</th>\n",
       "      <th>Topic4</th>\n",
       "      <th>Topic5</th>\n",
       "      <th>Topic6</th>\n",
       "      <th>Topic7</th>\n",
       "      <th>Dominant_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASUS TUF Gaming F15 Core i5 10th Gen - (8 GB/5...</td>\n",
       "      <td>1</td>\n",
       "      <td>Horrible</td>\n",
       "      <td>value for money laptop battery backup is low b...</td>\n",
       "      <td>negative</td>\n",
       "      <td>value for money laptop battery backup low that...</td>\n",
       "      <td>0.7906</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.1962</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASUS TUF Gaming F15 Core i5 10th Gen - (8 GB/5...</td>\n",
       "      <td>1</td>\n",
       "      <td>Worthless</td>\n",
       "      <td>best gaming lappy in low price range with good...</td>\n",
       "      <td>negative</td>\n",
       "      <td>best gaming lappy low price range good graphic</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.9462</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS TUF Gaming F15 Core i5 10th Gen - (8 GB/5...</td>\n",
       "      <td>1</td>\n",
       "      <td>Utterly Disappointed</td>\n",
       "      <td>best laptop at this price range pros new ryzen...</td>\n",
       "      <td>negative</td>\n",
       "      <td>best laptop price range pro new ryzen processo...</td>\n",
       "      <td>0.9828</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS TUF Gaming F15 Core i5 10th Gen - (8 GB/5...</td>\n",
       "      <td>1</td>\n",
       "      <td>Useless product</td>\n",
       "      <td>delivered without defect and arrived on timebe...</td>\n",
       "      <td>negative</td>\n",
       "      <td>delivered without defect arrived timebest valu...</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.3599</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.5954</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS TUF Gaming F15 Core i5 10th Gen - (8 GB/5...</td>\n",
       "      <td>1</td>\n",
       "      <td>Worthless</td>\n",
       "      <td>this laptop is very nice and good looking perf...</td>\n",
       "      <td>negative</td>\n",
       "      <td>laptop nice good looking performance also good</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.9386</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6864</th>\n",
       "      <td>ASUS TUF Gaming A17 with 90Whr Battery Ryzen 5...</td>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>performance was great display and sound qualit...</td>\n",
       "      <td>negative</td>\n",
       "      <td>performance great display sound quality good p...</td>\n",
       "      <td>0.8883</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.1035</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6865</th>\n",
       "      <td>MSI GF63 Thin Core i5 11th Gen - (8 GB/512 GB ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Absolute rubbish!</td>\n",
       "      <td>poor battery</td>\n",
       "      <td>negative</td>\n",
       "      <td>poor battery</td>\n",
       "      <td>0.7855</td>\n",
       "      <td>0.0357</td>\n",
       "      <td>0.0358</td>\n",
       "      <td>0.0358</td>\n",
       "      <td>0.0357</td>\n",
       "      <td>0.0357</td>\n",
       "      <td>0.0358</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6866</th>\n",
       "      <td>Lenovo IdeaPad Gaming Core i5 11th Gen - (8 GB...</td>\n",
       "      <td>4</td>\n",
       "      <td>Pretty good</td>\n",
       "      <td>screen bleeding issue</td>\n",
       "      <td>negative</td>\n",
       "      <td>screen bleeding issue</td>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.8569</td>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.0239</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6867</th>\n",
       "      <td>Lenovo IdeaPad Gaming Core i5 11th Gen - (8 GB...</td>\n",
       "      <td>2</td>\n",
       "      <td>Bad quality</td>\n",
       "      <td>let me start by saying this is not my first ga...</td>\n",
       "      <td>negative</td>\n",
       "      <td>let start saying first gaming laptop 3rd gamin...</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.9916</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6868</th>\n",
       "      <td>Lenovo IdeaPad Gaming Core i5 11th Gen - (8 GB...</td>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>nice</td>\n",
       "      <td>negative</td>\n",
       "      <td>nice</td>\n",
       "      <td>0.0715</td>\n",
       "      <td>0.0716</td>\n",
       "      <td>0.0715</td>\n",
       "      <td>0.5711</td>\n",
       "      <td>0.0715</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>0.0715</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6869 rows  14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            ProductName  Rate  \\\n",
       "0     ASUS TUF Gaming F15 Core i5 10th Gen - (8 GB/5...     1   \n",
       "1     ASUS TUF Gaming F15 Core i5 10th Gen - (8 GB/5...     1   \n",
       "2     ASUS TUF Gaming F15 Core i5 10th Gen - (8 GB/5...     1   \n",
       "3     ASUS TUF Gaming F15 Core i5 10th Gen - (8 GB/5...     1   \n",
       "4     ASUS TUF Gaming F15 Core i5 10th Gen - (8 GB/5...     1   \n",
       "...                                                 ...   ...   \n",
       "6864  ASUS TUF Gaming A17 with 90Whr Battery Ryzen 5...     5   \n",
       "6865  MSI GF63 Thin Core i5 11th Gen - (8 GB/512 GB ...     1   \n",
       "6866  Lenovo IdeaPad Gaming Core i5 11th Gen - (8 GB...     4   \n",
       "6867  Lenovo IdeaPad Gaming Core i5 11th Gen - (8 GB...     2   \n",
       "6868  Lenovo IdeaPad Gaming Core i5 11th Gen - (8 GB...     5   \n",
       "\n",
       "                    Review                                            Summary  \\\n",
       "0                 Horrible  value for money laptop battery backup is low b...   \n",
       "1                Worthless  best gaming lappy in low price range with good...   \n",
       "2     Utterly Disappointed  best laptop at this price range pros new ryzen...   \n",
       "3          Useless product  delivered without defect and arrived on timebe...   \n",
       "4                Worthless  this laptop is very nice and good looking perf...   \n",
       "...                    ...                                                ...   \n",
       "6864   Best in the market!  performance was great display and sound qualit...   \n",
       "6865     Absolute rubbish!                                       poor battery   \n",
       "6866           Pretty good                              screen bleeding issue   \n",
       "6867           Bad quality  let me start by saying this is not my first ga...   \n",
       "6868              Terrific                                               nice   \n",
       "\n",
       "     Sentiment                                     cleaned_review  Topic1  \\\n",
       "0     negative  value for money laptop battery backup low that...  0.7906   \n",
       "1     negative     best gaming lappy low price range good graphic  0.0090   \n",
       "2     negative  best laptop price range pro new ryzen processo...  0.9828   \n",
       "3     negative  delivered without defect arrived timebest valu...  0.0089   \n",
       "4     negative     laptop nice good looking performance also good  0.0102   \n",
       "...        ...                                                ...     ...   \n",
       "6864  negative  performance great display sound quality good p...  0.8883   \n",
       "6865  negative                                       poor battery  0.7855   \n",
       "6866  negative                              screen bleeding issue  0.0239   \n",
       "6867  negative  let start saying first gaming laptop 3rd gamin...  0.0014   \n",
       "6868  negative                                               nice  0.0715   \n",
       "\n",
       "      Topic2  Topic3  Topic4  Topic5  Topic6  Topic7  Dominant_topic  \n",
       "0     0.0027  0.1962  0.0026  0.0026  0.0026  0.0026               1  \n",
       "1     0.0090  0.0089  0.0089  0.0090  0.0090  0.9462               7  \n",
       "2     0.0029  0.0029  0.0029  0.0029  0.0029  0.0029               1  \n",
       "3     0.0089  0.3599  0.0089  0.0089  0.0089  0.5954               7  \n",
       "4     0.0103  0.0102  0.0103  0.0102  0.0102  0.9386               7  \n",
       "...      ...     ...     ...     ...     ...     ...             ...  \n",
       "6864  0.0016  0.1035  0.0016  0.0016  0.0016  0.0016               1  \n",
       "6865  0.0357  0.0358  0.0358  0.0357  0.0357  0.0358               1  \n",
       "6866  0.8569  0.0239  0.0238  0.0238  0.0238  0.0239               2  \n",
       "6867  0.0014  0.0014  0.0014  0.9916  0.0014  0.0014               5  \n",
       "6868  0.0716  0.0715  0.5711  0.0715  0.0714  0.0715               4  \n",
       "\n",
       "[6869 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(laptop)\n",
    "##Thus, we got which review is dominated by which topic. \n",
    "#The next step would be to find out what those topics are related to\n",
    "#That is we see what topic a review belongs to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddec634",
   "metadata": {},
   "source": [
    "# Step4: Find out keywords related to each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e8dfff59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 23225)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#.components gives the component of each cluster (i.e. topic) and a relevance score\n",
    "#If we arrange them in descending order of relevance score, we would be able to recongnize which keywords has \n",
    "#the highest relevance with a particular topic and hence we would be able to identify the approx topic\n",
    "lda_model.components_.shape\n",
    "\n",
    "#we can verify it from the shape of components, it is 10x23576 i.e no of clusters (topics) x no of words in the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "07dfbf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the components\n",
    "laptop_topic_keywords = pd.DataFrame(lda_model.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0c6768c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign Column and Index\n",
    "laptop_topic_keywords.columns = vectorizer.get_feature_names_out()\n",
    "laptop_topic_keywords.index = topic_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "30cc9230",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframe for topic number\n",
    "laptop_topic_no = pd.DataFrame(laptop_topic_keywords.idxmax()) #return index of keyword with maximum component\n",
    "\n",
    "#Create dataframe for relevance score\n",
    "laptop_scores = pd.DataFrame(laptop_topic_keywords.max()) #return the keyword with maximum component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f102d03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>relevance_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0100</th>\n",
       "      <td>Topic5</td>\n",
       "      <td>3.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0100 le</th>\n",
       "      <td>Topic5</td>\n",
       "      <td>3.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Topic1</td>\n",
       "      <td>24.306386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10 100</th>\n",
       "      <td>Topic7</td>\n",
       "      <td>4.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10 15</th>\n",
       "      <td>Topic2</td>\n",
       "      <td>3.142865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero people</th>\n",
       "      <td>Topic7</td>\n",
       "      <td>1.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zero withing</th>\n",
       "      <td>Topic5</td>\n",
       "      <td>3.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoom</th>\n",
       "      <td>Topic6</td>\n",
       "      <td>8.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoom using</th>\n",
       "      <td>Topic6</td>\n",
       "      <td>3.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zoom vdo</th>\n",
       "      <td>Topic6</td>\n",
       "      <td>5.142857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23225 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               topic  relevance_score\n",
       "0100          Topic5         3.142857\n",
       "0100 le       Topic5         3.142857\n",
       "10            Topic1        24.306386\n",
       "10 100        Topic7         4.142857\n",
       "10 15         Topic2         3.142865\n",
       "...              ...              ...\n",
       "zero people   Topic7         1.142857\n",
       "zero withing  Topic5         3.142857\n",
       "zoom          Topic6         8.142857\n",
       "zoom using    Topic6         3.142857\n",
       "zoom vdo      Topic6         5.142857\n",
       "\n",
       "[23225 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a dataframe to combine above DFs\n",
    "topic_relevance_scores = pd.merge(laptop_topic_no, laptop_scores, left_index=True, right_index=True)\n",
    "topic_relevance_scores.columns = ['topic', 'relevance_score']\n",
    "\n",
    "display(topic_relevance_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3d2be023",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This dataframe containss each word in the vocabulary and the topic it belongs to\n",
    "#A review is a mixture of such words, hence it will be a mixture of topics\n",
    "#Now, for each topic, I would order our dataframe in descending order and select the keywords with the highest score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7e294148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>relevance_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>battery</th>\n",
       "      <td>Topic1</td>\n",
       "      <td>386.300716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>backup</th>\n",
       "      <td>Topic1</td>\n",
       "      <td>297.061474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best</th>\n",
       "      <td>Topic1</td>\n",
       "      <td>283.268809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>battery backup</th>\n",
       "      <td>Topic1</td>\n",
       "      <td>272.609605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>Topic1</td>\n",
       "      <td>202.588397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <td>Topic1</td>\n",
       "      <td>120.744790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best laptop</th>\n",
       "      <td>Topic1</td>\n",
       "      <td>117.873253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poor</th>\n",
       "      <td>Topic1</td>\n",
       "      <td>105.140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>range</th>\n",
       "      <td>Topic1</td>\n",
       "      <td>104.311434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price range</th>\n",
       "      <td>Topic1</td>\n",
       "      <td>95.939128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 topic  relevance_score\n",
       "battery         Topic1       386.300716\n",
       "backup          Topic1       297.061474\n",
       "best            Topic1       283.268809\n",
       "battery backup  Topic1       272.609605\n",
       "price           Topic1       202.588397\n",
       "bad             Topic1       120.744790\n",
       "best laptop     Topic1       117.873253\n",
       "poor            Topic1       105.140000\n",
       "range           Topic1       104.311434\n",
       "price range     Topic1        95.939128"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>relevance_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>Topic2</td>\n",
       "      <td>737.771188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gaming</th>\n",
       "      <td>Topic2</td>\n",
       "      <td>279.316676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>only</th>\n",
       "      <td>Topic2</td>\n",
       "      <td>212.561922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>display</th>\n",
       "      <td>Topic2</td>\n",
       "      <td>192.096274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hour</th>\n",
       "      <td>Topic2</td>\n",
       "      <td>160.614411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>issue</th>\n",
       "      <td>Topic2</td>\n",
       "      <td>123.814831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>game</th>\n",
       "      <td>Topic2</td>\n",
       "      <td>116.303279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>Topic2</td>\n",
       "      <td>115.581018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laptop for</th>\n",
       "      <td>Topic2</td>\n",
       "      <td>102.518583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for gaming</th>\n",
       "      <td>Topic2</td>\n",
       "      <td>96.823708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             topic  relevance_score\n",
       "for         Topic2       737.771188\n",
       "gaming      Topic2       279.316676\n",
       "only        Topic2       212.561922\n",
       "display     Topic2       192.096274\n",
       "hour        Topic2       160.614411\n",
       "issue       Topic2       123.814831\n",
       "game        Topic2       116.303279\n",
       "one         Topic2       115.581018\n",
       "laptop for  Topic2       102.518583\n",
       "for gaming  Topic2        96.823708"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>relevance_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>money</th>\n",
       "      <td>Topic3</td>\n",
       "      <td>412.501796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for money</th>\n",
       "      <td>Topic3</td>\n",
       "      <td>397.733501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value</th>\n",
       "      <td>Topic3</td>\n",
       "      <td>388.445202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value for</th>\n",
       "      <td>Topic3</td>\n",
       "      <td>371.639793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beast</th>\n",
       "      <td>Topic3</td>\n",
       "      <td>84.735339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>big</th>\n",
       "      <td>Topic3</td>\n",
       "      <td>59.725162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram</th>\n",
       "      <td>Topic3</td>\n",
       "      <td>59.443722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>come</th>\n",
       "      <td>Topic3</td>\n",
       "      <td>42.611013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>happy</th>\n",
       "      <td>Topic3</td>\n",
       "      <td>41.268767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best value</th>\n",
       "      <td>Topic3</td>\n",
       "      <td>40.871301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             topic  relevance_score\n",
       "money       Topic3       412.501796\n",
       "for money   Topic3       397.733501\n",
       "value       Topic3       388.445202\n",
       "value for   Topic3       371.639793\n",
       "beast       Topic3        84.735339\n",
       "big         Topic3        59.725162\n",
       "ram         Topic3        59.443722\n",
       "come        Topic3        42.611013\n",
       "happy       Topic3        41.268767\n",
       "best value  Topic3        40.871301"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>relevance_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>product</th>\n",
       "      <td>Topic4</td>\n",
       "      <td>516.109818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nice</th>\n",
       "      <td>Topic4</td>\n",
       "      <td>295.371525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nice product</th>\n",
       "      <td>Topic4</td>\n",
       "      <td>165.582506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst</th>\n",
       "      <td>Topic4</td>\n",
       "      <td>105.434779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>Topic4</td>\n",
       "      <td>93.244461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flipkart</th>\n",
       "      <td>Topic4</td>\n",
       "      <td>81.099680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>Topic4</td>\n",
       "      <td>79.087521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thing</th>\n",
       "      <td>Topic4</td>\n",
       "      <td>75.510838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dont buy</th>\n",
       "      <td>Topic4</td>\n",
       "      <td>65.724446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fast</th>\n",
       "      <td>Topic4</td>\n",
       "      <td>60.301557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               topic  relevance_score\n",
       "product       Topic4       516.109818\n",
       "nice          Topic4       295.371525\n",
       "nice product  Topic4       165.582506\n",
       "worst         Topic4       105.434779\n",
       "great         Topic4        93.244461\n",
       "flipkart      Topic4        81.099680\n",
       "like          Topic4        79.087521\n",
       "thing         Topic4        75.510838\n",
       "dont buy      Topic4        65.724446\n",
       "fast          Topic4        60.301557"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>relevance_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>go</th>\n",
       "      <td>Topic5</td>\n",
       "      <td>120.349166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>go for</th>\n",
       "      <td>Topic5</td>\n",
       "      <td>102.217085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>problem</th>\n",
       "      <td>Topic5</td>\n",
       "      <td>90.475448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>Topic5</td>\n",
       "      <td>88.542337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>using</th>\n",
       "      <td>Topic5</td>\n",
       "      <td>80.752975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>Topic5</td>\n",
       "      <td>79.417859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>working</th>\n",
       "      <td>Topic5</td>\n",
       "      <td>76.998398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>much</th>\n",
       "      <td>Topic5</td>\n",
       "      <td>66.472921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>got</th>\n",
       "      <td>Topic5</td>\n",
       "      <td>65.390627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power</th>\n",
       "      <td>Topic5</td>\n",
       "      <td>57.694465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          topic  relevance_score\n",
       "go       Topic5       120.349166\n",
       "go for   Topic5       102.217085\n",
       "problem  Topic5        90.475448\n",
       "just     Topic5        88.542337\n",
       "using    Topic5        80.752975\n",
       "month    Topic5        79.417859\n",
       "working  Topic5        76.998398\n",
       "much     Topic5        66.472921\n",
       "got      Topic5        65.390627\n",
       "power    Topic5        57.694465"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>relevance_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>laptop</th>\n",
       "      <td>Topic6</td>\n",
       "      <td>636.611410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buy</th>\n",
       "      <td>Topic6</td>\n",
       "      <td>152.577992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>excellent</th>\n",
       "      <td>Topic6</td>\n",
       "      <td>110.198446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dont</th>\n",
       "      <td>Topic6</td>\n",
       "      <td>98.428006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>Topic6</td>\n",
       "      <td>94.701758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wifi</th>\n",
       "      <td>Topic6</td>\n",
       "      <td>59.150715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>without</th>\n",
       "      <td>Topic6</td>\n",
       "      <td>40.759862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>looking</th>\n",
       "      <td>Topic6</td>\n",
       "      <td>36.803728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>excellent product</th>\n",
       "      <td>Topic6</td>\n",
       "      <td>36.142498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>camera</th>\n",
       "      <td>Topic6</td>\n",
       "      <td>30.954313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    topic  relevance_score\n",
       "laptop             Topic6       636.611410\n",
       "buy                Topic6       152.577992\n",
       "excellent          Topic6       110.198446\n",
       "dont               Topic6        98.428006\n",
       "day                Topic6        94.701758\n",
       "wifi               Topic6        59.150715\n",
       "without            Topic6        40.759862\n",
       "looking            Topic6        36.803728\n",
       "excellent product  Topic6        36.142498\n",
       "camera             Topic6        30.954313"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>relevance_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>Topic7</td>\n",
       "      <td>1154.652208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>performance</th>\n",
       "      <td>Topic7</td>\n",
       "      <td>335.545049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good product</th>\n",
       "      <td>Topic7</td>\n",
       "      <td>227.475358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quality</th>\n",
       "      <td>Topic7</td>\n",
       "      <td>178.732084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>also</th>\n",
       "      <td>Topic7</td>\n",
       "      <td>143.664801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awesome</th>\n",
       "      <td>Topic7</td>\n",
       "      <td>135.784133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ok</th>\n",
       "      <td>Topic7</td>\n",
       "      <td>108.668899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good laptop</th>\n",
       "      <td>Topic7</td>\n",
       "      <td>101.712119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sound</th>\n",
       "      <td>Topic7</td>\n",
       "      <td>93.954953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>Topic7</td>\n",
       "      <td>90.411569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               topic  relevance_score\n",
       "good          Topic7      1154.652208\n",
       "performance   Topic7       335.545049\n",
       "good product  Topic7       227.475358\n",
       "quality       Topic7       178.732084\n",
       "also          Topic7       143.664801\n",
       "awesome       Topic7       135.784133\n",
       "ok            Topic7       108.668899\n",
       "good laptop   Topic7       101.712119\n",
       "sound         Topic7        93.954953\n",
       "low           Topic7        90.411569"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(topic_names)):\n",
    "    topic_i = topic_relevance_scores.loc[topic_relevance_scores['topic'] == 'Topic{}'.format(i+1)]\n",
    "    topic_i_sorted = topic_i.sort_values('relevance_score', ascending = False)\n",
    "    display(topic_i_sorted.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0becac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Next, lets map keywords and broad topics and add it to our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "61abc670",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Topic 1: Battery life\n",
    "#Topic 2: Display\n",
    "#Topic 3: Value for money\n",
    "#Topic 4: Overall product\n",
    "#Topic 5: Service\n",
    "#Topic 6: Wifi\n",
    "#Topic 7: Quality & Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "75ce94b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProductName</th>\n",
       "      <th>Rate</th>\n",
       "      <th>Review</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>Topic1</th>\n",
       "      <th>Topic2</th>\n",
       "      <th>Topic3</th>\n",
       "      <th>Topic4</th>\n",
       "      <th>Topic5</th>\n",
       "      <th>Topic6</th>\n",
       "      <th>Topic7</th>\n",
       "      <th>Dominant_topic</th>\n",
       "      <th>Dominant Topic Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASUS TUF Gaming F15 Core i5 10th Gen - (8 GB/5...</td>\n",
       "      <td>1</td>\n",
       "      <td>Horrible</td>\n",
       "      <td>value for money laptop battery backup is low b...</td>\n",
       "      <td>negative</td>\n",
       "      <td>value for money laptop battery backup low that...</td>\n",
       "      <td>0.7906</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.1962</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>1</td>\n",
       "      <td>Battery life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASUS TUF Gaming F15 Core i5 10th Gen - (8 GB/5...</td>\n",
       "      <td>1</td>\n",
       "      <td>Worthless</td>\n",
       "      <td>best gaming lappy in low price range with good...</td>\n",
       "      <td>negative</td>\n",
       "      <td>best gaming lappy low price range good graphic</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.9462</td>\n",
       "      <td>7</td>\n",
       "      <td>Quality &amp; Performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS TUF Gaming F15 Core i5 10th Gen - (8 GB/5...</td>\n",
       "      <td>1</td>\n",
       "      <td>Utterly Disappointed</td>\n",
       "      <td>best laptop at this price range pros new ryzen...</td>\n",
       "      <td>negative</td>\n",
       "      <td>best laptop price range pro new ryzen processo...</td>\n",
       "      <td>0.9828</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>1</td>\n",
       "      <td>Battery life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS TUF Gaming F15 Core i5 10th Gen - (8 GB/5...</td>\n",
       "      <td>1</td>\n",
       "      <td>Useless product</td>\n",
       "      <td>delivered without defect and arrived on timebe...</td>\n",
       "      <td>negative</td>\n",
       "      <td>delivered without defect arrived timebest valu...</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.3599</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.5954</td>\n",
       "      <td>7</td>\n",
       "      <td>Quality &amp; Performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS TUF Gaming F15 Core i5 10th Gen - (8 GB/5...</td>\n",
       "      <td>1</td>\n",
       "      <td>Worthless</td>\n",
       "      <td>this laptop is very nice and good looking perf...</td>\n",
       "      <td>negative</td>\n",
       "      <td>laptop nice good looking performance also good</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.9386</td>\n",
       "      <td>7</td>\n",
       "      <td>Quality &amp; Performance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6864</th>\n",
       "      <td>ASUS TUF Gaming A17 with 90Whr Battery Ryzen 5...</td>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>performance was great display and sound qualit...</td>\n",
       "      <td>negative</td>\n",
       "      <td>performance great display sound quality good p...</td>\n",
       "      <td>0.8883</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.1035</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>1</td>\n",
       "      <td>Battery life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6865</th>\n",
       "      <td>MSI GF63 Thin Core i5 11th Gen - (8 GB/512 GB ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Absolute rubbish!</td>\n",
       "      <td>poor battery</td>\n",
       "      <td>negative</td>\n",
       "      <td>poor battery</td>\n",
       "      <td>0.7855</td>\n",
       "      <td>0.0357</td>\n",
       "      <td>0.0358</td>\n",
       "      <td>0.0358</td>\n",
       "      <td>0.0357</td>\n",
       "      <td>0.0357</td>\n",
       "      <td>0.0358</td>\n",
       "      <td>1</td>\n",
       "      <td>Battery life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6866</th>\n",
       "      <td>Lenovo IdeaPad Gaming Core i5 11th Gen - (8 GB...</td>\n",
       "      <td>4</td>\n",
       "      <td>Pretty good</td>\n",
       "      <td>screen bleeding issue</td>\n",
       "      <td>negative</td>\n",
       "      <td>screen bleeding issue</td>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.8569</td>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.0239</td>\n",
       "      <td>2</td>\n",
       "      <td>Display</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6867</th>\n",
       "      <td>Lenovo IdeaPad Gaming Core i5 11th Gen - (8 GB...</td>\n",
       "      <td>2</td>\n",
       "      <td>Bad quality</td>\n",
       "      <td>let me start by saying this is not my first ga...</td>\n",
       "      <td>negative</td>\n",
       "      <td>let start saying first gaming laptop 3rd gamin...</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.9916</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>5</td>\n",
       "      <td>Service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6868</th>\n",
       "      <td>Lenovo IdeaPad Gaming Core i5 11th Gen - (8 GB...</td>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>nice</td>\n",
       "      <td>negative</td>\n",
       "      <td>nice</td>\n",
       "      <td>0.0715</td>\n",
       "      <td>0.0716</td>\n",
       "      <td>0.0715</td>\n",
       "      <td>0.5711</td>\n",
       "      <td>0.0715</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>0.0715</td>\n",
       "      <td>4</td>\n",
       "      <td>Overall product</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6869 rows  15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            ProductName  Rate  \\\n",
       "0     ASUS TUF Gaming F15 Core i5 10th Gen - (8 GB/5...     1   \n",
       "1     ASUS TUF Gaming F15 Core i5 10th Gen - (8 GB/5...     1   \n",
       "2     ASUS TUF Gaming F15 Core i5 10th Gen - (8 GB/5...     1   \n",
       "3     ASUS TUF Gaming F15 Core i5 10th Gen - (8 GB/5...     1   \n",
       "4     ASUS TUF Gaming F15 Core i5 10th Gen - (8 GB/5...     1   \n",
       "...                                                 ...   ...   \n",
       "6864  ASUS TUF Gaming A17 with 90Whr Battery Ryzen 5...     5   \n",
       "6865  MSI GF63 Thin Core i5 11th Gen - (8 GB/512 GB ...     1   \n",
       "6866  Lenovo IdeaPad Gaming Core i5 11th Gen - (8 GB...     4   \n",
       "6867  Lenovo IdeaPad Gaming Core i5 11th Gen - (8 GB...     2   \n",
       "6868  Lenovo IdeaPad Gaming Core i5 11th Gen - (8 GB...     5   \n",
       "\n",
       "                    Review                                            Summary  \\\n",
       "0                 Horrible  value for money laptop battery backup is low b...   \n",
       "1                Worthless  best gaming lappy in low price range with good...   \n",
       "2     Utterly Disappointed  best laptop at this price range pros new ryzen...   \n",
       "3          Useless product  delivered without defect and arrived on timebe...   \n",
       "4                Worthless  this laptop is very nice and good looking perf...   \n",
       "...                    ...                                                ...   \n",
       "6864   Best in the market!  performance was great display and sound qualit...   \n",
       "6865     Absolute rubbish!                                       poor battery   \n",
       "6866           Pretty good                              screen bleeding issue   \n",
       "6867           Bad quality  let me start by saying this is not my first ga...   \n",
       "6868              Terrific                                               nice   \n",
       "\n",
       "     Sentiment                                     cleaned_review  Topic1  \\\n",
       "0     negative  value for money laptop battery backup low that...  0.7906   \n",
       "1     negative     best gaming lappy low price range good graphic  0.0090   \n",
       "2     negative  best laptop price range pro new ryzen processo...  0.9828   \n",
       "3     negative  delivered without defect arrived timebest valu...  0.0089   \n",
       "4     negative     laptop nice good looking performance also good  0.0102   \n",
       "...        ...                                                ...     ...   \n",
       "6864  negative  performance great display sound quality good p...  0.8883   \n",
       "6865  negative                                       poor battery  0.7855   \n",
       "6866  negative                              screen bleeding issue  0.0239   \n",
       "6867  negative  let start saying first gaming laptop 3rd gamin...  0.0014   \n",
       "6868  negative                                               nice  0.0715   \n",
       "\n",
       "      Topic2  Topic3  Topic4  Topic5  Topic6  Topic7  Dominant_topic  \\\n",
       "0     0.0027  0.1962  0.0026  0.0026  0.0026  0.0026               1   \n",
       "1     0.0090  0.0089  0.0089  0.0090  0.0090  0.9462               7   \n",
       "2     0.0029  0.0029  0.0029  0.0029  0.0029  0.0029               1   \n",
       "3     0.0089  0.3599  0.0089  0.0089  0.0089  0.5954               7   \n",
       "4     0.0103  0.0102  0.0103  0.0102  0.0102  0.9386               7   \n",
       "...      ...     ...     ...     ...     ...     ...             ...   \n",
       "6864  0.0016  0.1035  0.0016  0.0016  0.0016  0.0016               1   \n",
       "6865  0.0357  0.0358  0.0358  0.0357  0.0357  0.0358               1   \n",
       "6866  0.8569  0.0239  0.0238  0.0238  0.0238  0.0239               2   \n",
       "6867  0.0014  0.0014  0.0014  0.9916  0.0014  0.0014               5   \n",
       "6868  0.0716  0.0715  0.5711  0.0715  0.0714  0.0715               4   \n",
       "\n",
       "        Dominant Topic Name  \n",
       "0              Battery life  \n",
       "1     Quality & Performance  \n",
       "2              Battery life  \n",
       "3     Quality & Performance  \n",
       "4     Quality & Performance  \n",
       "...                     ...  \n",
       "6864           Battery life  \n",
       "6865           Battery life  \n",
       "6866                Display  \n",
       "6867                Service  \n",
       "6868        Overall product  \n",
       "\n",
       "[6869 rows x 15 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insights for Topic Modelling\n",
    "\n",
    "# Map the topic names to the dominant topics\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "equiv = {1: 'Battery life', 2: 'Display', 3: 'Value for money', 4: 'Overall product', 5: 'Service', 6: 'Wifi', 7: 'Quality & Performance'}\n",
    "#laptop = laptop.DataFrame( {\"Dominant_topic\": [1, 2, 3, 4, 5, 6, 7]} )\n",
    "laptop[\"Dominant Topic Name\"] = laptop[\"Dominant_topic\"].map(equiv)\n",
    "\n",
    "laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5f36c727",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAF9CAYAAAD1K0SPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABBUElEQVR4nO3dd5xU5dn/8c9XQAEVG+ijImLsUkWwd2OLikajYjT2EEtiSX5RjHliiSYmsZtiNBZ8YsHYYzQSC1ZsICrFGokSsWHDhpTr98e5Zx3W3Z3ZMntmlu/79ZrXzpxz5pxrZmfmOnc5962IwMzMrCmL5R2AmZlVPycLMzMrycnCzMxKcrIwM7OSnCzMzKwkJwszMyvJyaKKSbpU0v/mHUd7k3S6pL+2ch9t/t5JWknSQ5JmSzqvLffd0UjqI+kTSZ1yOPa2kma093E7OieLZpK0paTHJH0k6X1Jj0oa1gb7PVTSI8XLIuKoiPhla/fdgljK/rGWNE7SB5KWqHRczVGh924k8B7QIyJ+Un+lpKslndXGx0TSdEnfbOv9pn0fKml++mH/WNKzknZv7X4j4vWIWCoi5rdFnHlL34mQtHEVxNGqE6mWcrJoBkk9gDuBS4DlgVWBM4A5ecaVF0l9ga2AAIbnG027WB2YGh3vStbxEbEUsCzwR+AGScvmGlEVkSTge8D7wCE5h5OfiPCtzBswFPiwxDaHA9OAD4B7gNWL1gVwFPByWv8HQMD6wBfAfOCTwjGAq4Gz0v1tgRnAScA7wExgL+BbwEtkH+SfFR1rMWAU8CowC7gRWD6t65tiOQR4nexs+dS0bhfgS2BuiuXZJl7rL4BHgfOBO+utuzq9vn8As4EngDWL1l8EvAF8DEwAtipadzrw13T/H8CP6u37ufTaBVyQ3o+P0vL+Dbx3PcmS/IfpfXoYWKyR17Q58FTa31PA5kX7m5vem0+Abzbw3LpjNrCu1Ou9CRiT3quJwKC07v+ABcDn6bgnpeXDgSnpNY0D1i/a33TgFGAq2efsKqBrI3EdCjxS9Lh7+mwMS4+XAM5Nn5O3gUuBbmndNGD3oud2JvssDeGrz1jntG4Z4Aqyz+1/gbOATmndf4CN0v2D0vM2SI+PBG5L9zcGnk7v4dvA+Y28pm3Jvis/S/FMBw5M64al53Yu2n4fYFITn/Ot0/t/ENl3afGidWsBD6bPy3vAmHrf9+OAf6d1v6Poc0fTvxX9gH+RfV7fTq+l7O9mRX7/2vNgtX4DeqQPy2hgV2C5euv3Al4h+/HvDPwceKzeh+dOsjO4PsC7wC5p3UJf2rTsahZOFvPIfqC7AN9Pz78OWDp9uL4AvpG2PwF4HOhN9oX/M3B9Wtc3xXI50A0YRFY6Wj+tP530Y13i/XgFOAbYKH2AV6oX+/tkX/DOwLXADUXrDwJWSOt+ArxF+kFj4WSxH/BE0fMGFb6wwM5kP7zL8lXSXbmB9+7XZD9yXdJtK0ANvJ7lyb6430txHZAer1B/n428H42uL+P1zgW+k+L7f8BrQJe0fjpFyQlYB/gU2DFtf1L6XyxetP1kYLX0mh5tIq5DSZ87oBNwLNkP0opp2YXAHWk/SwN/B36d1v0CuLZoX7sBL9T7jBWSxW1kn8ElgRWBJ4EfpHXXAD9J9y8jO8E5umjdien+eOB76f5SwKaNvKZtyb4r55N99rdJ79e6af1UYNei7W8tHL+R/V1BdrLVheyzt3fRuuuBU8lOzroCW9b7vj+Q3rs+ZCd1R5b6rUjv80yyz0nX9HiT5nw3K/L7l8dBa/mW/rlXk525zEtfpJXSuruBI4q2XQz4jHTGkD48xR+mG4FR6X7dl7Zo/dUsnCw+56uzsaXT/jYp2n4CsFe6Pw3YoWjdymQ/SJ356ovcu2j9k8CIcj+QwJZpfz3T4xcKX+qi2P9S9PhbpB+SRvb3AV+dTdcdn+zL/j6wdnp8LvDHdH/79AXclHolhXrv3ZnA7cBaJV7T94An6y0bDxxaf5+NPL/J9SVe7+P1PjczSaUPvp4s/he4sd72/wW2Ldr+qHrv/auNxHEo2ef4w/T//BzYL60T2Y9scYlwM+C1dH8tspJQ9/T4WuAX6X7hM9YZWInsZKRb0X4OAB5I948A7ij63B5JOrEgK3UMSfcfIqv27Vnivd02vaYl633X/jfdP5mU5Mh+yD8jnWQ0sK/uZCWZwvfqz8DtReuvIUtwvRt4bpBOBtPjY4D7osRvRXpvnmkkntPJKVm4zaKZImJaRBwaEb2B/sAqZGdfkP2jL5L0oaQPyX7kRNa2UfBW0f3PyM6QyjUrvmow/Dz9fbto/edF+1sduLUolmlk1VwrtVEshwBjI+K99Pg6vl6f2+j+Jf1E0rTUUeBDsmqKnvUPEhFzyL7oB0lajOyL9H9p3f3A78mqu96WdFlqV6rvd2RncWMl/VvSqEZe0ypkP07F/sPC/78WKeP1vlG4ExELyE5GViknzrT9G/XifKPo/n+a2BdkiWpZYDmyk5+t0vJeZD+WE4o+R/9My4mIV8g+V3tI6k5WNXZdA/tfneysfGbRfv5MVsKArBpnK0n/Q1a6GQNskdrElgEmpe2OICtVvSDpqRIN8R9ExKeNvAd/TTEvRVZyfTgiZjayn2+TJZ670uNrgV0l9UqPTyL7jj8paYqkw+s9v7H/Q1O/FauRla6qipNFK0TEC2Rnk/3TojfIitbLFt26RcRj5eyujcN7g6yoXRxL14j4b2tjkdSN7Eu2jaS3JL0FnAgMkjSo1M4lbUV2drcfWVXesmR1vmrkKaOBA4EdgM8iYnxdoBEXR8RGZNVw6wA//dqLiZgdET+JiG8AewA/lrRDA8d5k+xLXKwP2Vl7i5X5elcr2n4xsurDNwsvoak4UwPsavXiXK3ofp+ifTUqIj4hO/v9nqQNyerZPwf6FX2GlomsMbzgerIEvidZ4/8rDez6DbKSRc+i/fSIiH7puK+QnUwcBzwUEbPJTjRGkpW2F6TtXo6IA8iSzG+AmyQt2cjLWa7eurr3IH0HxpMlgu+RTj4acQjZSc7r6XP+N7LEd0Da11sR8f2IWAX4AfBHSWsVPb+x/0NTvxVvAGs2Ek9b/06UzcmiGSStl84Qe6fHq5F9aB5Pm1wKnCKpX1q/jKR9y9z920BvSYu3UbiXAmdLWj3F0kvSns2IpW/60WrIXmSllA2Awem2PlnD8cFl7H9psrO1d4HOkn5B1h7UoJQcFgDnUfTFljRM0iaSupBVlxQ6CSxE0u6S1ko/qh+nbRrq0nkXsI6k70rqLGn/9BrvLOM1FXSS1LXotniZr3cjSXtL6kzW3jSHrz5XbwPfKNr2RmA3STuk1/6TtH3xScmxknpLWp6scXRMOcFHxCzgL2TVSQvI2rUukLQigKRVJe1c9JQbgJ2Ao2m4VEE6ax8LnCeph6TFJK0paZuizR4Efpj+QtZoX/wYSQdJ6pXi+jAtbqpr7hmSFk/JeneyH/qCa8hKBQPI2iy+RtKqZCcou/PV53wQWaI6JG2zb+H3gKxqMerF9FNJy6XfiuP56v/Q1G/FncD/SDpB0hKSlpa0SVpX6rtZMU4WzTMb2AR4QtKnZF/myWRfViLiVrIP0g2SPk7rdi1z3/eT9W55S9J7pTYuw0VkVQpjJc1OsW7S9FPqFL5UsyRNbGD9IcBVkfWlf6twI6sSOjD94DXlHrI625fIiuZfsHBxvSHXkH2xi/uY9yD7Mfsg7WcWWZtGfWsD95L1IBlP1uYxrv5G6Ydyd7L/5yyyH5Pdi6rayjGK7Gy8cLuf8l7v7cD+fNXAvndEzE3rfg38PFVZ/L+IeJGswfwSsrP/PYA9IuLLov1dR/YD/e90a871HxcC35I0kKxE9ArwePpM3wusW9gwJYLxZL3ImkpIB5N1Sij00LqJrB2t4EGypPpQI48h6w00RdInZJ/vERHxRSPHeysd502yqqOjUk1Awa2kqtp61VXFvkfWS2psvc/5xcBASf3Jelc9kWK6Azg+Il4r2sftZG2Jk8h69l0BTf9WpJLVjmT/17fIek9ul/ZX6rtZMUqNJmZVTdLBwMiI2DLvWNqapNPJGt8PaqP9TSfrdXNvW+yvo5L0KllVUEXeJ0lB1jGjoaq5muOShVW91Hh6DFmvE7NWk7QPWZXR/XnHUiucLKyqpfrxd8nqahusEzdrDknjgD8BxxYaz620ilVDSbqSrP73nYjon5YtT1av2ZesL/h+EfFBWncKWde4+cBxEXFPWr4RWY+jbmQNkMeH687MzNpVJUsWV5M1SBUbRXZRytrAfekxkjYARpB1f9yFrPtZYbTKP5F1oVs73erv08zMKqxUr5UWi4iH0kU1xfYku7oSsr7z48h6W+xJdsXmHOA1Sa8AG6eGuh6FfvWSriHrtnl3qeP37Nkz+vatf3gzM2tMz549ueeee+6JiK+dlFcsWTRipcKVkhExs9B3m+yqxceLtpuRls1N9+svb5CkkWSlEPr06cPTTz/dhqGbmXV8kr42kgJUTwN3Q1fuRhPLGxQRl0XE0IgY2qtXr8Y2MzOzZmrvZPG2pJUB0t930vIZLHxZfGGogxnpfv3lZmbWjto7WdzBV4PNHUJ2dWNh+Yh0afsaZA3ZT6Yqq9mSNk1DNRxc9BwzM2snFWuzkHQ9WWN2T2Xz4Z4GnAPcKOkIsslU9gWIiCmSbiQbCmAeWf/nwvgqR/NV19m7KaNx28w6vrlz5zJjxgy++KKxET+sKV27dqV379506dKlrO077HAfQ4cODTdwm3Vcr732GksvvTQrrLACWcWDlSsimDVrFrNnz2aNNdZYaJ2kCRExtP5zqqWB28ysWb744gsnihaSxAorrNCsUpmThZnVLCeKlmvue+dkYWZmJTlZmNki6eyzz6Zfv34MHDiQwYMH88QTTzR7H5MmTeKuu+6qe3zHHXdwzjnntGWYXzNu3Dgee6ycyTfbVntfwW1mZZi23volt1n/hWntEEnHNH78eO68804mTpzIEksswXvvvceXX35Z+on1TJo0iaeffppvfetbAAwfPpzhw4e3dbgLGTduHEsttRSbb755RY9Tn0sWZrbImTlzJj179mSJJZYAsjGRVlllFSZMmMA222zDRhttxM4778zMmTMB2HbbbTn55JPZeOONWWeddXj44Yf58ssv+cUvfsGYMWMYPHgwY8aM4eqrr+aHP/whAIceeihHH3002223Hd/4xjd48MEHOfzww1l//fU59NBD62IZO3Ysm222GUOGDGHfffflk08+AaBv376cdtppDBkyhAEDBvDCCy8wffp0Lr30Ui644AIGDx7Mww8/3G7vmZOFmS1ydtppJ9544w3WWWcdjjnmGB588EHmzp3Lj370I2666SYmTJjA4Ycfzqmnnlr3nHnz5vHkk09y4YUXcsYZZ7D44otz5plnsv/++zNp0iT233//rx3ngw8+4P777+eCCy5gjz324MQTT2TKlCk8//zzTJo0iffee4+zzjqLe++9l4kTJzJ06FDOP//8uuf37NmTiRMncvTRR3PuuefSt29fjjrqKE488UQmTZrEVltt1S7vF7gayswWQUsttRQTJkzg4Ycf5oEHHmD//ffn5z//OZMnT2bHHXcEYP78+ay88lfThO+9994AbLTRRkyfPr2s4+yxxx5IYsCAAay00koMGDAAgH79+jF9+nRmzJjB1KlT2WKLLQD48ssv2WyzzRo85i233NLq190aThZmtkjq1KkT2267Ldtuuy0DBgzgD3/4A/369WP8+PENbl+osurUqRPz5s0r6xiF5yy22GJ19wuP582bR6dOndhxxx25/vrr2+yYleJqKDNb5Lz44ou8/PLLdY8nTZrE+uuvz7vvvluXLObOncuUKVOa3M/SSy/N7NmzWxzHpptuyqOPPsorr7wCwGeffcZLL71U0WO2lJOFmS1yPvnkEw455BA22GADBg4cyNSpUznzzDO56aabOPnkkxk0aBCDBw8u2UV1u+22Y+rUqXUN3M3Vq1cvrr76ag444AAGDhzIpptuygsvvNDkc/bYYw9uvfXWdm/g9thQZlXIXWdLmzZtGuuvX/p9ssY19B56bCgzM2sxJwszMyvJycLMzEpysjAzs5KcLMzMrCQnCzMzK8lXcJtZh9B31D/adH/Tz9mt5DadOnViwIABzJs3j/XXX5/Ro0fTvXv3so/x5ptvctxxx3HTTTcxadIk3nzzzboRbO+44w6mTp3KqFGjWvwa2pJLFmZmLdStWzcmTZrE5MmTWXzxxbn00kub9fxVVlmFm266Cfj63BjDhw+vmkQBThZmZm1iq6224pVXXuH9999nr732qrsi+7nnngPgwQcfZPDgwQwePJgNN9yQ2bNnM336dPr379/kcOcfffQRffv2ZcGCBUA2JMhqq63G3LlzefXVV9lll13YaKON2GqrrUpe/d0aThZmZq00b9487r77bgYMGMBpp53GhhtuyHPPPcevfvUrDj74YADOPfdc/vCHPzBp0iQefvhhunXrVvf8poY7X2aZZRg0aBAPPvggAH//+9/Zeeed6dKlCyNHjuSSSy5hwoQJnHvuuRxzzDEVe41uszAza6HPP/+cwYMHA1nJ4ogjjmCTTTbh5ptvBmD77bdn1qxZfPTRR2yxxRb8+Mc/5sADD2Tvvfemd+/eZR9n//33Z8yYMWy33XbccMMNHHPMMXzyySc89thj7LvvvnXbzZkzp01fXzEnCzOzFiq0WRRraLw9SYwaNYrddtuNu+66i0033ZR7772Xrl27lnWc4cOHc8opp/D+++8zYcIEtt9+ez799FOWXXbZrx2/UlwNZWbWhrbeemuuvfZaIJsvu2fPnvTo0YNXX32VAQMGcPLJJzN06NCvtS80NfT4UkstxcYbb8zxxx/P7rvvTqdOnejRowdrrLEGf/vb34AsST377LMVe10uWZhZh1BOV9f2cPrpp3PYYYcxcOBAunfvzujRowG48MILeeCBB+jUqRMbbLABu+66a90c35ANd37OOecwePBgTjnllK/td//992ffffdl3LhxdcuuvfZajj76aM466yzmzp3LiBEjGDRoUEVel4coN6tCHqK8NA9R3noeotzMzNqUk4WZmZXkZGFmZiU5WZiZWUlOFmZmVpKThZmZleTrLMysYzh9mTbe30clN5HEj3/8Y8477zwgG//pk08+4fTTT2/TUH71q1/xs5/9rO7x5ptvzmOPPdamxygll5KFpBMlTZE0WdL1krpKWl7SvyS9nP4uV7T9KZJekfSipJ3ziNnMrL4llliCW265hffee6+ix/nVr3610OP2ThSQQ7KQtCpwHDA0IvoDnYARwCjgvohYG7gvPUbSBml9P2AX4I+SOrV33GZm9XXu3JmRI0dywQUXfG3du+++yz777MOwYcMYNmwYjz76aN3yHXfckSFDhvCDH/yA1VdfvS7Z7LXXXmy00Ub069ePyy67DIBRo0bVDVh44IEHAtnwH5Bd1V08B8ahhx7KzTffzPz58/npT3/KsGHDGDhwIH/+859b/VrzarPoDHST1BnoDrwJ7AmMTutHA3ul+3sCN0TEnIh4DXgF2Lh9wzUza9ixxx7Ltddey0cfLVxtdfzxx3PiiSfy1FNPcfPNN3PkkUcCcMYZZ7D99tszceJEvv3tb/P666/XPefKK69kwoQJPP3001x88cXMmjWLc845p27AwsKYUwUjRoxgzJgxAHz55Zfcd999fOtb3+KKK65gmWWW4amnnuKpp57i8ssv57XXXmvV62z3NouI+K+kc4HXgc+BsRExVtJKETEzbTNT0orpKasCjxftYkZa9jWSRgIjAfr06VOpl2BmVqdHjx4cfPDBXHzxxQvNUXHvvfcyderUuscff/wxs2fP5pFHHuHWW28FYJdddmG55epq3Ln44ovr1r3xxhu8/PLLrLDCCo0ee9ddd+W4445jzpw5/POf/2TrrbemW7dujB07lueee65uFr6PPvqIl19+mTXWWKPFr7Pdk0Vqi9gTWAP4EPibpIOaekoDyxoc0CoiLgMug2xsqNZFamZWnhNOOIEhQ4Zw2GGH1S1bsGAB48ePXyiBQMNDmEM2Qu29997L+PHj6d69O9tuuy1ffPFFk8ft2rUr2267Lffccw9jxozhgAMOqDvGJZdcws47t10Tbx7VUN8EXouIdyNiLnALsDnwtqSVAdLfd9L2M4DVip7fm6zaysysKiy//PLst99+XHHFFXXLdtppJ37/+9/XPS7MO7Hlllty4403AjB27Fg++OADIDv7X2655ejevTsvvPACjz/+VYVKly5dmDt3boPHHjFiBFdddRUPP/xwXXLYeeed+dOf/lT3nJdeeolPP/20Va8xj66zrwObSupOVg21A/A08ClwCHBO+nt72v4O4DpJ5wOrAGsDT7Z30GZW5cro6lpJP/nJTxZKDhdffDHHHnssAwcOZN68eWy99dZceumlnHbaaRxwwAGMGTOGbbbZhpVXXpmll16aXXbZhUsvvZSBAwey7rrrsummm9bta+TIkQwcOJAhQ4Z8rd1ip5124uCDD2b48OEsvvjiABx55JFMnz6dIUOGEBH06tWL2267rVWvL5chyiWdAewPzAOeAY4ElgJuBPqQJZR9I+L9tP2pwOFp+xMi4u5Sx/AQ5VbLPER5abU6RPmcOXPo1KkTnTt3Zvz48Rx99NHtNttdfc0ZojyXi/Ii4jTgtHqL55CVMhra/mzg7ErHZWZWaa+//jr77bcfCxYsYPHFF+fyyy/PO6Sy+ApuM7N2tPbaa/PMM8/kHUazeWwoMzMrycnCzMxKcrIwM7OSnCzMzKwkN3CbWYcwYPSANt3f84c8X3Kbthyi/MMPP+S6667jmGOOafZz+/bty9NPP03Pnj2b/dxyuWRhZtZCbTlE+Ycffsgf//jHBtfNnz+/1ftvLScLM7MWaskQ5aeffjrnnntu3Xb9+/dn+vTpjBo1ildffZXBgwfz05/+lHHjxrHddtvx3e9+lwEDslJTQ0OYtxdXQ5mZtUJhSI+TTjppoeWFIcq33HJLXn/9dXbeeWemTWv8qvtzzjmHyZMn113NPW7cOJ588kkmT55cN1rslVdeyfLLL8/nn3/OsGHD2GeffZoclbYtOVmYmbVCc4cob46NN954oWHFmzuEeVtysjAza6XmDFHeuXNnFixYUPe4qWHIl1xyybr7LRnCvC25zcLMrJWaM0R53759mThxIgATJ06sm8Fu6aWXbrLk0dQQ5u2hWSULSYsBS0XExxWKx8ysRcrp6lpJ5Q5Rvs8++3DNNdcwePBghg0bxjrrrAPACiuswBZbbEH//v3Zdddd2W233Rbaf1NDmLeHkkOUS7oOOAqYD0wAlgHOj4jfVT68lvMQ5VbLPER5abU6RHk1ac4Q5eVUQ22QShJ7AXeRzTfxvTaI08zMakQ5yaKLpC5kyeL2NBWq57c2M1uElJMs/gxMB5YEHpK0OuA2CzPLXR4zfXYUzX3vSiaLiLg4IlaNiG9FtvfXge1aGJ+ZWZvo2rUrs2bNcsJogYhg1qxZdO3ateznlOwNJelV4HHgYeChiJhKNhe2mVluevfuzYwZM3j33XfzDqUmde3ald69e5e9fTldZzcANgG2As6VtB7wbER8u2Uhmpm1XpcuXRa6utkqq5w2i/nA3PR3AfA28E4lgzIzs+pSTsniY+B54Hzg8oiYVdmQzMys2pRTsjgAeAg4BrhB0hmSdqhsWGZmVk1Kliwi4nbg9tRWsStwAnAS0K2p55mZWcdRsmQh6ebUI+oismstDgaWq3RgZmZWPcppszgHmBgR+c/rZ2ZmuSgnWUwBTpHUJyJGSlobWDci7qxwbFZlPLid2aKrnGRxFdlos5unxzOAvwFOFlb1yklw4CRnVko5vaHWjIjfkl1rQUR8DqiiUZmZWVUpp2TxpaRupJFmJa0JzKloVB2cq3PMrNaUkyxOA/4JrCbpWmAL4NBKBmVmZtWlnOss/iVpIrApWfXT8RHxXsUjMzOzqtFom0W6CA9JQ4DVgZnAm0CftMzMzBYRTZUsfgyMBM5rYF0A21ckIjMzqzqNJouIGJn+tvlER5KWBf4C9CdLPIcDLwJjgL5kM/PtFxEfpO1PAY4gG/n2uIi4p61jMjOzxpUz3Mezkk5JvaDaykXAPyNiPWAQMA0YBdwXEWsD96XHSNoAGAH0A3YB/iipUxvGYmZmJZRzncVwsjP6GyU9Jen/SerT0gNK6gFsDVwBEBFfRsSHwJ7A6LTZaGCvdH9P4IaImBMRrwGvABu39PhmZtZ85czB/Z+I+G1EbAR8FxgIvNaKY34DeBe4StIzkv4iaUlgpYiYmY45E1gxbb8q8EbR82ekZV8jaaSkpyU97akWzczaTjklCyT1lXQScAOwHtkQ5S3VGRgC/CkiNgQ+JVU5NXb4BpY1OEN7RFwWEUMjYmivXr1aEaKZmRUreZ2FpCeALmTjQe0bEf9u5TFnADMi4on0+CayZPG2pJUjYqaklflq6tYZwGpFz+9N1oXXzMzaSTkli0MiYkhE/LoNEgUR8RbwhqR106IdgKnAHcAhhWMCt6f7dwAjJC0haQ1gbeDJ1sZhZmblK2e4jw8kXQGsEhG7pt5Jm0XEFa047o+AayUtDvwbOIwscd0o6QjgdWBfgIiYIulGsoQyDzjWc2uYmbWvcpLF1WTDlJ+aHr9Edj1Ei5NFREwChjawqsG5vSPibODslh7PzMxap5xqqJ4RcSOwACAi5pF1pTUzs0VEOcniU0kr8NUQ5ZsCH1U0KjMzqyrlVEP9mKyReU1JjwK9gO9UNCozM6sq5QxRPlHSNsC6ZNc8vIivoDYzW6Q0mizS+Ev7kV0tfXfqlbQ7cBnQDdiwfUI0M7O8NVWyuILsYrgngUsk/YdsAqRTIuK2dojNzMyqRFPJYigwMCIWSOoKvAeslS6qMzOzRUhTvaG+jIhCd9kvgJecKMzMFk1NlSzWk/Rcui+y3lDPpfsREQMrHp2ZmTVq2nrrl9xm/RemtcmxmkoWpaMwM7NFQlPTqv6nPQMxM7PqVdZ8FmZmtmhzsjAzs5IaTRaS7kt/f9N+4ZiZWTVqqoF75TTMx3BJN1BvetOImFjRyMzMrGo0lSx+QTbdaW/g/HrrAti+UkGZmVl1aao31E3ATZL+NyJ+2Y4xmZm1q/a8XqFWlTPq7C8lDQe2TovGRcSdlQ3LzMyqScneUJJ+DRxPNgf2VOD4tMzMzBYR5Ux+tBswuDBOlKTRwDPAKZUMzMzMqke511ksW3R/mQrEYWZmVaycksWvgWckPUDWfXZrXKowM1uklNPAfb2kccAwsmRxsocqN2vE6WUUvE//qPJxmLWxckoWRMRM4I4Kx2JmZlXKY0OZmVlJThZmZlZSk8lC0mKSJrdXMGZmVp2aTBbp2opnJfVpp3jMzKwKldPAvTIwRdKTwKeFhRExvGJRmZlZVSknWZxR8SjMzKyqlXOdxYOSVgfWjoh7JXUHOlU+NDMzqxblDCT4feAm4M9p0arAbRWMyczMqkw5XWePBbYAPgaIiJeBFSsZlJmZVZdyksWciPiy8EBSZ7KZ8szMbBFRTrJ4UNLPgG6SdgT+Bvy9smGZmVk1Kac31CjgCOB54AfAXcBfWntgSZ2Ap4H/RsTukpYHxgB9genAfhHxQdr2lBTDfOC4iLintcc3s7bn6Uk7rnJ6Qy1IEx49QVb99GJEtEU11PHANKBHejwKuC8izpE0Kj0+WdIGwAigH7AKcK+kdSJifhvEYGZmZSinN9RuwKvAxcDvgVck7dqag0rqTTYDX3EJZU9gdLo/GtiraPkNETEnIl4DXgE2bs3xzcysecqphjoP2C4iXgGQtCbwD+DuVhz3QuAkYOmiZSulodCJiJmSCj2uVgUeL9puRlr2NZJGAiMB+vTxCCVmZm2lnAbudwqJIvk38E5LDyhp97TPCeU+pYFlDVaDRcRlETE0Iob26tWrpSGamVk9jZYsJO2d7k6RdBdwI9mP9L7AU6045hbAcEnfAroCPST9FXhb0sqpVLEyXyWkGcBqRc/vDbzZiuObmVkzNVWy2CPdugJvA9sA2wLvAsu19IARcUpE9I6IvmQN1/dHxEFkM/EdkjY7BLg93b8DGCFpCUlrAGsDT7b0+GZm1nyNliwi4rD2DAQ4B7hR0hHA62QlGCJiiqQbganAPOBY94QyM2tfJRu409n8j8iuf6jbvi2GKI+IccC4dH8WsEMj250NnN3a45mZWcuU0xvqNuAKsqu2F1Q0GjMzq0rlJIsvIuLiikdiZmZVq5xkcZGk04CxwJzCwoiYWLGozMysqpSTLAYA3wO256tqqEiPzcxsEVBOsvg28I3iYcrNzGzRUs4V3M8Cy1Y4DjMzq2LllCxWAl6Q9BQLt1m0uuusmZnVhnKSxWkVj8LMzKpaOfNZPNgegZiZWfUq5wru2Xw1yuviQBfg04jo0fizzMysIymnZFE85wSS9sKTD5mZLVLK6Q21kIi4DV9jYWa2SCmnGmrvooeLAUNpZPIhMzPrmMrpDbVH0f15wHSyebHNzGwRUU6bRXvPa2Ft6fRlytjmo8rHYWY1ralpVX/RxPMiIn5ZgXjMzKwKNVWy+LSBZUsCRwArAE4WZmaLiKamVT2vcF/S0sDxwGHADcB5jT3PrE24+sysqjTZZiFpeeDHwIHAaGBIRHzQHoGZmVn1aKrN4nfA3sBlwICI+KTdojIzs6rS1EV5PwFWAX4OvCnp43SbLenj9gnPzMyqQVNtFs2+utvMzDqmci7KMyivwRXc6GpmHZJLD2ZmVpKThZmZleRkYWZmJTlZmJlZSU4WZmZWkpOFmZmV5GRhZmYlOVmYmVlJThZmZlaSk4WZmZXkZGFmZiW1+9hQklYDrgH+B1gAXBYRF6W5M8YAfYHpwH6FuTMknUI2Q9984LiIuKe94zYzazM1OLlXHiWLecBPImJ9YFPgWEkbAKOA+yJibeC+9Ji0bgTQD9gF+KOkTjnEbWa2yGr3ZBERMyNiYro/G5gGrArsSTYbH+nvXun+nsANETEnIl4DXgE2btegzcwWcbkOUS6pL7Ah8ASwUkTMhCyhSFoxbbYq8HjR02akZQ3tbyQwEqBPnz4VitrMqkYNVufUqtwauCUtBdwMnBARTc28pwaWRUMbRsRlETE0Iob26tWrLcI0MzNyShaSupAlimsj4pa0+G1JK6f1KwPvpOUzgNWKnt4beLO9YjUzsxyShSQBVwDTIuL8olV3AIek+4cAtxctHyFpCUlrAGsDT7ZXvGZmlk+bxRbA94DnJU1Ky34GnAPcKOkI4HVgX4CImCLpRmAqWU+qYyNifrtHbWa2CGv3ZBERj9BwOwTADo0852zg7IoFZbaoc0OxleAruM3MrCQnCzMzK8nJwszMSnKyMDOzkpwszMysJCcLMzMrycnCzMxKcrIwM7OSnCzMzKykXIcoN1sUDRg9oOQ2N7ZDHGbN4ZKFmZmV5GRhZmYlOVmYmVlJThZmZlaSG7itZrmh2Kz9uGRhZmYlOVmYmVlJThZmZlaS2yzamOvRzawjcsnCzMxKcrIwM7OSnCzMzKwkt1lYWe0s4LYWs0WZk4WZdWjudNI2nCzMzKpQtSU5t1mYmVlJThZmZlaSq6HMrCzVVi1i7cslCzMzK8nJwszMSnKyMDOzkpwszMysJCcLMzMrycnCzMxKcrIwM7OSaiZZSNpF0ouSXpE0Ku94zMwWJTWRLCR1Av4A7ApsABwgaYN8ozIzW3TUyhXcGwOvRMS/ASTdAOwJTM01KmuRvqP+UXKb6V3bIRAzK5siIu8YSpL0HWCXiDgyPf4esElE/LDediOBkenhusCL7RpopifwXg7HbY1ajBkcd3tz3O0rj7jfA4iIXeqvqJWShRpY9rUsFxGXAZdVPpzGSXo6IobmGUNz1WLM4Ljbm+NuX9UWd020WQAzgNWKHvcG3swpFjOzRU6tJIungLUlrSFpcWAEcEfOMZmZLTJqohoqIuZJ+iFwD9AJuDIipuQcVmNyrQZroVqMGRx3e3Pc7auq4q6JBm4zM8tXrVRDmZlZjpwszMysJCcLM+tQJPXPO4aOyMmilSStI+k+SZPT44GSfp53XB2RpPvKWVZtlDlI0i/S4z6SNs47rg7sUklPSjpG0rJ5B9NROFm03uXAKcBcgIh4jqxrb1WTdK6kfnnHUQ5JXSUtD/SUtJyk5dOtL7BKzuGV44/AZsAB6fFssrHOaoKk1SV9M93vJmnpvGNqSkRsCRxIdm3W05Kuk7RjzmE1SlKP9Hf5hm55x1dQE11nq1z3iHhSWugi83l5BdMMLwCXSeoMXAVcHxEf5RxTY34AnECWGCbw1RX9H1MbP7qbRMQQSc8ARMQH6Xqhqifp+2RD6CwPrEl2QeylwA55xlVKRLycSvhPAxcDGyr7kv4sIm7JN7qvuQ7YneyzHSw8YkUA38gjqPqcLFrvPUlrkoYfSeNYzcw3pNIi4i/AXyStCxwGPCfpUeDyiHgg3+gWFhEXARdJ+lFEXJJ3PC0wN42cXPiM9AIW5BtS2Y4lG8jzCaj7EV4x35CaJmkg2Wd6N+BfwB4RMVHSKsB4oNqSxTnp7/oR8UWukTTB1VCtdyzwZ2A9Sf8lOwM+KteIypR+wNZLt/eAZ4Efp1F9q9GC4jroVCV1TI7xlOti4FZgRUlnA48Av8o3pLLNiYgvCw9SSbTaL876PTARGBQRx0bERICIeBOoxvbEi9Lfx3KNogRflNdCko6PiIskbRERj0paElgsImbnHVs5JJ0PDAfuA66IiCeL1r0YEevmFlwjJE2KiMH1lj0TERvmFFLZJK1HVnUj4L6ImJZzSGWR9FvgQ+Bg4EfAMcDUiDg1z7hKkdQN6BMReYw83SySHgemkZWEvnaiFhHHtXtQDXCyaKHCD5ekiRExJO94mkvS4cANEfFZA+uWqcb2C0nPkZ0tFqpzOgHPRURVN9RL2hSYUjiRSA3EG0TEE/lGVpqkxYAjgJ3IEt09wF+iin84JO0BnAssHhFrSBoMnBkRw/ONrGGSegLfBH4D/KL++ogY3e5BNcDJooUkXU/Ww6UX8GrxKiAiYmAugTWDpOWAtYG6qYYi4qH8ImqapN8BfckaWIOsuu+NiPhJnnGVkhq2hxQlucWAp2vhJCOVmL+IiPnpcSdgiYZOMqqFpAnA9sC4QqlT0nPV/p2UNCgins07jsa4gbuFIuIASf9DdqZVlWcsTZF0JHA8We+WScCmZI1/2+cYViknk/WMOposKY8F/pJrROVR8Zl4RCxIdf+14D6ys95P0uNuZO/75rlFVNq8iPioXg/FqiXppIj4LXCkpIbm6amKaqha+cBWpYh4CxiUdxwtdDwwDHg8IrZLdepn5BxTkyJiAfCndKsl/5Z0HF/FfQzw7xzjaY6uEVFIFETEJ5K65xlQGSZL+i7QSdLawHFUd+PxEpKGkXUw+ZKGJ3vLnZNFC0m6MSL2k/Q8C/cOqZVqqC8i4gtJSFoiIl5I3WirlqTXaHiGxKroh96Eo8h6RP2cLP77+Gr632r3qaQhhR5FkjYCPs85plJ+BJwKzAGuJyv9/zLXiJq2DFmPqPXJEsZjwKPA+Ih4P8/AirnNooUkrRwRMyWt3tD6iPhPe8fUHJJuJeuLfgJZ1dMHQJeI+FaecTVF0gpFD7sC+wLLR8TXGgWtbaQz3hv4ambKlYH9I2JCflF1TOlCzaFkVXybpduHEbFBroElThaGpG3Izm7+WdynvhZIeiQN71C10kV43ydrnK8rzUfE4XnF1BySugDrkpWaX4iIuTmH1CRJ6wD/j6+/39XcHoekZcgSxBbp77LA8xFxWJ5xFbgaqoUkzabhi5MK1VA92jmksjQy1szz6e9SQNUUe+uTVNx7aDGys7CqHqcouR14GLgXmJ9zLGWRtH1E3C9p73qr1pZEFQ6ZUexvZD3m/kINvN+SLgP6kY0Z9gRZNdT5EfFBroHV42TRQhFRCz9SDWlo/JmCqhmHphHnFd2fB0wH9ssnlGbpHhEn5x1EM20D3A/s0cC6oPqGzCg2LyJqqRNEH2AJ4GXgv8AMsgshq4qrocwqTNJZwGMRcVfesTSXpE6FayxqhaTTgXfIhliZU1heTY3F9aVBDvuRtVdsDvQnK+WPj4jT8oytwMliEZaqGLYkO1N8OCJuyzeihkn6cVPrI+L89oqlJVKV5ZJkP1xzqfKqymKSXgf+CYwB7q/mK7cLUq+5+qIGes0hqTdZm8XmZCPRrhARy+YaVOJksYiS9EdgLbKuhQD7A69GxLH5RdUwSYUzq3XJrg25Iz3eA3goIo7MJbBFQBpjaQ+yOVqGAHeSDRPzSK6BdSDpGpzNyZLEXFK32fT3+XR9Ue6cLFpJ0g+Ba6utMaoUSVOA/vWGoHi+msdZkjQW2KfeGEt/i4hd8o2stFobWqUh6TVcBBwYEZ3yjqcxqffW0cDWadE44M/V2osrDer5GPBoRFTt9AZu4G69/wGekjQRuBK4pxaK6sCLZA1rhetBVgOeyy+csvQhu8K14Euy7pFVrUaHVqmTulbvD+wKPEX1dyr4E9CFbIZCgO+lZVVZAo2IJqtZq4VLFm0gNU7tRHaR21DgRrJhv19t8ok5kvQgWZVOYWjyYWQ/YJ8BVOMInZJOJfuhujUt2gsYExG/zi2oMqSr/AtDqwwuDK0SEfvnHFpJqf5/Etln+o6I+DTfiEqT9GxEDCq1zJrHJYs2EBEh6S3gLbIuncsBN0n6V0SclG90jaq5q54j4mxJdwNbkTXKHxYRz+QcVjlqbmgVqBth9qqIODPvWJppvqQ1Cydrkr5BDVxvUe2cLFopNU4dQjbT3F+An0bE3NQG8DJQrcniaeDzNALqOmSz5d1drfW6ReaTTUka1M7UpDOUzfB3G/AvSR/w1fAZVSsi5kvaDqi1ZPFT4AFJ/ybrebY6WanfWsHVUK0k6QzgyobGgpK0flTpjGhpzP+tyEpBj5Mlj88i4sBcA2uCpOPJhs24mexH4NvAZVFD83LX2tAqyqaBXYas62xdFVRhYMFqJWkJFh6iZE6Jp1gJThatkEoPz0VE/7xjaa7CDH+SfgR0i4jfqoFpS6tJmilvs0K9eZqYZ3wNjPBb6Em0GguPVVTVP7gAkh5oYHFU8zhLqfpsN74+NlRVX49T7VwN1QqpCudZSX0i4vW842kmSdoMOJBs2kyAqu0OmYiF657nU6Vj/xeT9EvgULI5LApVZ0EN9IaKiO3yjqEF/g58QTbmWa1UVVY9J4vWWxmYIulJFi6mV11vonpOAE4Bbo2IKakRsKGzyGpyJfBEGl4dst5QV+QXTtn2A9ashWqn+iStBPwKWCUidpW0AVnprprf9961UNqsNa6GaqVUB/01EfFge8fSkaUqv03Jzhi3JCtRPFQLvaEk3QwcHRHv5B1Lc6XeZ1cBp0bEoDQd7DMRMSDn0Bol6TfAfRExNu9YOhInizaQJkBaOyLuTVNOdipcZVxtJF0YESdI+jsNzzpXtSUiSeMjYrO842guSUPJhimfzMID21Xte10g6amIGCbpmYjYMC2r9ratbwN/JRvGvqbG4qpmroZqJUnfJ5sic3lgTWBVsrH0d8gzrib8X/p7bq5RtMxYSfsAt9TIVfIFo4HfUJt16J+mGQoLw8JsCnyUb0glnUc2edDzNfY5qWouWbSSpEnAxsATRWdez1dzMb0gzeBGRLybdyzlKBq9dT5ZdRTUwBmjpAcjosHqymqXJpy6hGzI7MlAL+A7EVG1Q8NIugfYtVoG4OsoXLJovTkR8WU24gekOt2qzcBpaJLTgB+SFc8XkzQPuKTar9St5QmnJP2abLTc4mqoqu06m+befiMiJqZ2uR8A+wBjySbnqWYzgXGpvaX4/XbX2VZwsmi9ByX9DOgmaUfgGLKue9XqBLKhkIdFxGtQNxzCnySdGBEX5BlcKbUyB0c9G6a/mxYtq/aus38Gvpnubw6cCvwIGAxcBnwnn7DK8lq6LZ5u1gZcDdVKqZfOEWQDCYps1NnL842qcZKeAXaMiPfqLe8FjC1UpVWjWpqDoyBdIHZctSfh+ooH3pP0B+DdiDg9Pa7qBm6rDJcsWu9HEXERUJcgJB2fllWjLvUTBWTtFmkegGq2DQvPwTGarNG4aqXxlYYDNZUsgE6SOkfEPLLOGiOL1vl3YxG0WN4BdACHNLDs0PYOohmaujCs2i8aK8zBUVALc3AAPCbp95K2kjSkcMs7qBKuJ6tivR34HHgYQNJaVH9vKKsAV0O1kKQDgO+S1Z8/XLRqaWB+RHyzwSfmTNJ8iq40L14FdI2Iqi1d1OIcHFCb4ytBXTfZlcmqJwvjca0DLFWtjfO1Wu1XC5wsWihdiLcG8GtgVNGq2WSDC87LJbAOrLGr5Qt81bwBSBoXEdvmHUdH42TRSpJ+ExEnl1pmiy5Jy5B1Vy7MCf0gcGZEuDqnAmp1WPVq52TRSoWhvuste84DmVlBGhtqMtmV3JDNCT0oIvbOL6qOq1ar/aqdk0ULSTqa7JqKNYFXilYtDTwaEQflEphVnYa6mrr7qdUad4FrueuAu2mgzSIi3s8nJKtSn0vaMiIeAZC0BVkPI6sAV/tVhksWbUTSikDXwuManAypakl6noaHUCmMJlrVVX6SBgHXkNWjA3wAHFLN4yvVMlf7VYaTRStJ2gM4H1gFeIdscvhpEdEv18A6kNTzrFHRwPzn1aBwcaakLSLiUUk9ACLi47xj68hc7VcZviiv9c4iG/PnpYhYg+xq10fzDaljiYj/NHXLO74mHJb+XgJZknCiaBefS9qy8MDVfm3DbRatNzciZklaTNJiEfFAmqnL2kgamrypaqhqHaJ8mqTpwIqSiqucaqL6rIYdBVyT2i4gVfvlGE+H4GTReh9KWgp4CLhW0juAL8hrQ7U6NHlEHCDpf4B7gKq8urwjKRqTbak0Bayr/dqQ2yxaSdKSZEXcxYADyRoxr42IWbkG1oHVUmeCNPzEaHelrrxCu0RD1z5Z67lk0UqFMXOABZL+AczyVI6VkUZvPY96nQmAqu1MkEad7Slp8Yio9oEaa12h2q+Xq/3anpNFC6VB1s4B3gd+STa3dU+ymecOjoh/5hlfB/VLss4E90bEhpK2Aw7IOaZy/Ad4VNIdLDz8hGdua0Ou9qssJ4uW+z3wM7Jqp/vJ5vx9XNJ6ZMM7O1m0vVrtTPBmui1GdoW/VUhEvAUMyjuOjsjJouU6R8RYAElnRsTjABHxQmE+bmtzNdmZICLOgKx9q6ja0qym+DqLlltQdL9+H263WVTGnmRzV5xIVnJ7Fdgj14jKIGkzSVPJ2leQNChNEWtWM9wbqoWKJhES0I00AQ81MIlQLUq9iu6p1kmlmiLpCeA7wB2FOc4lTY6I/vlG1rG5JNe2XLJooYjoFBE9ImLpiOic7hceO1G0sYiYD3xWdKFVTYmIN+otmp9LIIsASZu7JNf23GZhteQL4HlJ/2LhXkXH5RdSWd6QtDkQkhYHjiP9kFlFXADsDNwBEBHPStq66adYKU4WVkv+kW615ijgImBVYAYwFjg214g6uIh4o15HE5fkWsnJwmpGRIyW1A3oExEv5h1POSTtBawFXBMRB+YczqLCJbkKcJuF1Yw0HPwk0jUskganC92qUqonPxFYAfilpP/NOaRFxVFkJbdCSW4wLsm1mntDWc2QNAHYHhhX1Kvo+YgYkG9kDZM0mWzSnfmSugMPR8RGecdl1hKuhrJaMi8iPqpXF13NZztfpl5cRMRn8tWa7ULSVTTwuYiIw3MIp8NwsrBaMlnSd4FOktYmq4t+LOeYmrJe0YB2AtZMjz2wXWXdWXS/K/BtsuFWrBVcDWU1I1XlnArslBbdA5wVEV/kF1XjanU62I5G0mJkg09un3cstczJwmqGpA0j4pm847DaImld4B8RsVbesdQyV0NZLTlf0srA34AbImJK3gFZ9Smahlfp71vAybkG1QG4ZGE1Jc1XsB+wP9ADGBMRZ+UblVnH52RhNUnSAOAkYP+IWDzveJpL0gqeerdtSWpyKtWImNhesXREThZWMyStT1ai2Bd4D7gBuDki3sk1sDJJepVsuJK/AldHxAY5h9ShSHqgidXhBu7WcZuF1ZKryGYh3DEiaq4rZESsKelEYDxwWN7xdDQRsV3eMXRkLllYzUjjQq1J1mj5arV2mS2QNBb4fqGLbJq3fTTwO2CniNgvz/g6Mkn9gQ3IrrMAICKuyS+i2ueShVU9SZ2BX5Gdjb9ONqZZ73Sl7qkRMTfP+JqwYlGi2I0sSewRES9J+kG+oXVckk4DtiVLFncBuwKPAE4WreCBBK0W/A5YHvhGRGyUxoVaE1gWODfPwEqYI+kQST8nq0LbMSWKHsCSOcfWkX0H2AF4KyIOAwYBS+QbUu1zNZRVPUkvA+tEvQ9rmmr1hYhYO5/ImiZpLWAU8CXZfOG7Ag+RzSX+14i4IMfwOixJT0bExmngye2A2cDkiOiXc2g1zdVQVguifqJIC+dLqtqznYh4BTiy8FjS/cA3gZMj4t7cAuv4npa0LHA5MAH4BHgy14g6AJcsrOpJug24pX4DpaSDgP0iYngugVlVkfR74LqIeKxoWV+gR0Q81+gTrSxOFlb1JK0K3AJ8TnamGMAwoBvw7Yj4b47hWZWQdDwwAlgZGANcHxGTcg2qA3GysJohaXugH9mYP1Mi4r6cQ7IqlEb7HZFuXcmuzbkhIl7KNbAa52RhVmGSdgfuiogFeceyqJG0IXAlMDAiOuUdTy1z11mzyhsBvCzpt2nIEqsgSV0k7SHpWuBu4CVgn5zDqnkuWZi1g3RtxQFkFxYGaeiSiJida2AdiKQdyd7j3ch6P90A3BYRn+YaWAfhZGHWTiT1BA4CTgCmAWsBF0fEJXnG1VGkgQSvIxtc8v284+lonCzMKkzScLISxZrA/wGjI+KdNE3stIhocvpVs2rgi/LMKu87wAUR8VDxwoj4TNLhOcVk1ixu4DarvJn1E4Wk3wC4+6/VCicLs8rbsYFlu7Z7FGat4GooswqRdDRwDLCmpOLhJpYGHs0nKrOWcQO3WYVIWgZYDvg12eizBbPdW8dqjZOFWYVI6hERH0tavqH1ThhWS5wszCpE0p0Rsbuk18guxFPR6oiIb+QUmlmzOVmYmVlJbuA2qxBJQ5paHxET2ysWs9ZyycKsQtLwE42JiNi+3YIxayUnCzMzK8nVUGbtQFJ/YAOyyXgAqD9NrFk1c8nCrMIknQZsS5Ys7iK7evuRiPhOnnGZNYeH+zCrvO8AOwBvRcRhwCBgiXxDMmseJwuzyvs8Tak6L02C9A7gayysprjNwqzynpa0LHA5MAH4hGwmN7Oa4TYLs3YkqS/QIyKeK7WtWTVxsjCrMElbN7S8/hwXZtXMycKswiT9vehhV2BjYIIvyrNa4jYLswqLiD2KH0taDfhtTuGYtYh7Q5m1vxlA/7yDMGsOlyzMKkzSJWRDlEN2gjYYeDa3gMxawG0WZhUm6ZCih/OA6RHhaVWtpjhZmFWYpO7AWunhixExJ894zFrCbRZmFSKpi6QLgTeAq4DRwL8ljUrrN8wxPLNmccnCrEIkXQx0B06MiNlpWQ/gXGA+sEtErJFjiGZlc7IwqxBJrwBrR70vmaROwHvArhHxeC7BmTWTq6HMKmdB/UQBEBHzgXedKKyWOFmYVc5USQfXXyjpIGBaDvGYtZirocwqRNKqwC3A52SjzQYwDOgGfDsi/ptjeGbN4mRhVmGStgf6AQKmRMR9OYdk1mxOFmZmVpLbLMzMrCQnCzMzK8nJwqwFJH1bUkharx2OtaykYyp9HLOmOFmYtcwBwCPAiHY41rKAk4XlysnCrJkkLQVsARxBShaSVpb0kKRJkiZL2iot/0TSeZImSrpPUq+0fE1J/5Q0QdLDhRKKpJUk3Srp2XTbHDgHWDPt+3e5vGhb5Lk3lFkzpYvqtouIIyQ9BvwQ2A7oGhFnp+E8ukfEbEkBHBQR10r6BbBiRPxQ0n3AURHxsqRNgF9HxPaSxgDjI+LCtJ+lgOWAOyPCEyZZbjz5kVnzHQBcmO7fkB7/HbhSUhfgtoiYlNYvAMak+38Fbkklk82Bv0kq7HOJ9Hd74GCoGxbkI0nLVeyVmJXJycKsGSStQPaD3j+VGjqRXZl9ErA1sBvwf5J+FxHXNLCLIKv+/TAiBrdP1Gat5zYLs+b5DnBNRKweEX0jYjXgNbJE8U5EXA5cAQxJ2y+WngPwXeCRiPgYeE3SvgDKDErb3AccnZZ3SkOazwaWbofXZtYoJwuz5jkAuLXespuBq4FJkp4B9gEuSus+BfpJmkBWIjkzLT8QOELSs8AUYM+0/HhgO0nPk40n1S8iZgGPpoZzN3BbLtzAbVZBkj6JiKXyjsOstVyyMDOzklyyMDOzklyyMDOzkpwszMysJCcLMzMrycnCzMxKcrIwM7OS/j8h/Xrqsya6NQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the number of positive, negative, and neutral reviews for each of the 7 aspects\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Group the dataset by aspect and sentiment score\n",
    "grouped = laptop.groupby(['Dominant Topic Name', 'Sentiment'])\n",
    "\n",
    "# Count the number of reviews for each aspect and sentiment score\n",
    "counts = grouped.size().unstack(fill_value=0)\n",
    "\n",
    "# Plot the counts for each aspect and sentiment score\n",
    "counts.plot(kind='bar', width=0.8)\n",
    "\n",
    "# Set the plot title and labels\n",
    "plt.title('Sentiment Analysis of Laptop Reviews by Aspect')\n",
    "plt.xlabel('Aspect')\n",
    "plt.ylabel('Number of Reviews')\n",
    "\n",
    "# Set the x-axis labels\n",
    "x_labels = counts.index\n",
    "plt.xticks(range(len(x_labels)), x_labels)\n",
    "\n",
    "# Add legend\n",
    "plt.legend(title='Sentiment', loc='upper right', labels=['Positive', 'Negative', 'Neutral'])\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45e5048",
   "metadata": {},
   "source": [
    "#From above graph, we see that people are talking more about overall quality and performance -- this characteristic got highest number of reviews followed by display and battery life <br>\n",
    "#Value for money aspect got least negatuve reviews<br>\n",
    "#To extend this project, we can plot the graph product wise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "37bc73c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thus, by combining these two approaches we can find out sentiment and characteristics of a laptop review\n",
    "#Given a review, the LDA would provide dominant topic while RNN model would provide its sentiment, \n",
    "#the business would understand which areas they are good and which areas need improvements"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
